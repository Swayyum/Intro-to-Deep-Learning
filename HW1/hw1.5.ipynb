{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-30T18:09:15.775226600Z",
     "start_time": "2024-01-30T18:09:08.051537400Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 42\u001B[0m\n\u001B[0;32m     38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m train_data, train_labels, test_data, test_labels\n\u001B[0;32m     41\u001B[0m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m---> 42\u001B[0m \u001B[43mA\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mMLP\u001B[39;00m(nn\u001B[38;5;241m.\u001B[39mModule):\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n",
      "\u001B[1;31mNameError\u001B[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, f1_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_cifar10_batch(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict[b'data'], dict[b'labels']\n",
    "\n",
    "\n",
    "def load_cifar10_data(data_dir):\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        data_batch, label_batch = load_cifar10_batch(os.path.join(data_dir, f'data_batch_{i}'))\n",
    "        train_data.append(data_batch)\n",
    "        train_labels.append(label_batch)\n",
    "\n",
    "    train_data = np.concatenate(train_data)\n",
    "    train_labels = np.concatenate(train_labels)\n",
    "\n",
    "    test_data, test_labels = load_cifar10_batch(os.path.join(data_dir, 'test_batch'))\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32 * 32 * 3)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc4(self.relu(self.fc3(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cifar10_dir = r'C:\\Users\\SirM\\Desktop\\Swayam\\Intro To ML\\cifar-10-batches-py'\n",
    "\n",
    "    train_data, train_labels, test_data, test_labels = load_cifar10_data(cifar10_dir)\n",
    "    train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "    train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "    test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "    test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "    train_data /= 255.0\n",
    "    test_data /= 255.0\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(list(zip(train_data, train_labels)), batch_size=64, shuffle=True)\n",
    "    testloader = torch.utils.data.DataLoader(list(zip(test_data, test_labels)), batch_size=64, shuffle=False)\n",
    "\n",
    "model = MLP().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "val_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(f'Epoch {epoch + 1}, loss: {running_loss / len(trainloader)}')\n",
    "\n",
    "    train_loss.append(running_loss / len(trainloader))\n",
    "    train_accuracy.append(100 * correct / total)\n",
    "\n",
    "    # Validation accuracy\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)  # Calculate validation loss\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss.append(val_running_loss / len(testloader))\n",
    "    val_accuracy.append(100 * correct / total)\n",
    "\n",
    "# Evaluating the model\n",
    "y_pred = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy} %')\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d')\n",
    "\n",
    "# Plotting training loss and accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracy, label='Training Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "1\n",
    "B\n",
    "\n",
    "\n",
    "class MLP_extended(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_Deep_Wide, self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 1024)  # Increased width\n",
    "        self.fc2 = nn.Linear(1024, 512)  # Increased width\n",
    "        self.fc3 = nn.Linear(512, 256)  # Increased width\n",
    "        self.fc4 = nn.Linear(256, 128)  # Increased width\n",
    "        self.fc5 = nn.Linear(128, 64)  # Additional layer\n",
    "        self.fc6 = nn.Linear(64, 10)  # Additional layer, output matches the number of classes\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32 * 32 * 3)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.fc6(self.relu(self.fc5(x)))  # Pass through the additional layer\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cifar10_dir = r'C:\\Users\\SirM\\Desktop\\Swayam\\Intro To ML\\cifar-10-batches-py'\n",
    "\n",
    "    train_data, train_labels, test_data, test_labels = load_cifar10_data(cifar10_dir)\n",
    "    train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "    train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "    test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "    test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "    train_data /= 255.0\n",
    "    test_data /= 255.0\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(list(zip(train_data, train_labels)), batch_size=64, shuffle=True)\n",
    "    testloader = torch.utils.data.DataLoader(list(zip(test_data, test_labels)), batch_size=64, shuffle=False)\n",
    "\n",
    "model = MLP().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "val_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(f'Epoch {epoch + 1}, loss: {running_loss / len(trainloader)}')\n",
    "\n",
    "    train_loss.append(running_loss / len(trainloader))\n",
    "    train_accuracy.append(100 * correct / total)\n",
    "\n",
    "    # Validation accuracy\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)  # Calculate validation loss\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss.append(val_running_loss / len(testloader))\n",
    "    val_accuracy.append(100 * correct / total)\n",
    "\n",
    "# Evaluating the model\n",
    "y_pred = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy} %')\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d')\n",
    "\n",
    "# Plotting training loss and accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracy, label='Training Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load dataset\n",
    "df_train = pd.read_csv('C:/Users/SirM/Desktop/Swayam/Deep Learning/Intro-to-Deep-Learning/Datasets/house-train.csv')\n",
    "df_test = pd.read_csv('C:/Users/SirM/Desktop/Swayam/Deep Learning/Intro-to-Deep-Learning/Datasets/house-test.csv')\n",
    "\n",
    "# Define useful columns and preprocess the dataset\n",
    "usefull_cols = ['OverallQual', 'GrLivArea', 'GarageArea', 'TotalBsmtSF', 'FullBath',\n",
    "                'YearBuilt', 'YearRemodAdd', 'Fireplaces', 'LotFrontage', 'WoodDeckSF',\n",
    "                'OpenPorchSF']\n",
    "target_col = 'SalePrice'\n",
    "\n",
    "df_train_prepro = df_train[usefull_cols + [target_col]].copy()\n",
    "\n",
    "# Handle missing values\n",
    "df_train_prepro.fillna(df_train_prepro.mean(), inplace=True)\n",
    "\n",
    "# Split dataset into features and target\n",
    "X = df_train_prepro[usefull_cols]\n",
    "y = df_train_prepro[target_col]\n",
    "\n",
    "# Split data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor.view(-1, 1))\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor.view(-1, 1))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# MLP Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "model = MLP(len(usefull_cols))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            total_val_loss += loss.item()\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
