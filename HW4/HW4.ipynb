{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "english_to_french = [\n",
    "\n",
    "    (\"I am cold\", \"J'ai froid\"),\n",
    "\n",
    "    (\"You are tired\", \"Tu es fatigué\"),\n",
    "\n",
    "    (\"He is hungry\", \"Il a faim\"),\n",
    "\n",
    "    (\"She is happy\", \"Elle est heureuse\"),\n",
    "\n",
    "    (\"We are friends\", \"Nous sommes amis\"),\n",
    "\n",
    "    (\"They are students\", \"Ils sont étudiants\"),\n",
    "\n",
    "    (\"The cat is sleeping\", \"Le chat dort\"),\n",
    "\n",
    "    (\"The sun is shining\", \"Le soleil brille\"),\n",
    "\n",
    "    (\"We love music\", \"Nous aimons la musique\"),\n",
    "\n",
    "    (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
    "\n",
    "    (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
    "\n",
    "    (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
    "\n",
    "    (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
    "\n",
    "    (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
    "\n",
    "    (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
    "\n",
    "    (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
    "\n",
    "    (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
    "\n",
    "    (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
    "\n",
    "    (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
    "\n",
    "    (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
    "\n",
    "    (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
    "\n",
    "    (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
    "\n",
    "    (\"The book is on the table\", \"Le livre est sur la table\"),\n",
    "\n",
    "    (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
    "\n",
    "    (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
    "\n",
    "    (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
    "\n",
    "    (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
    "\n",
    "    (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
    "\n",
    "    (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
    "\n",
    "    (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
    "\n",
    "    (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
    "\n",
    "    (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
    "\n",
    "    (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
    "\n",
    "    (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
    "\n",
    "    (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
    "\n",
    "    (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
    "\n",
    "    (\"He paints landscapes\", \"Il peint des paysages\"),\n",
    "\n",
    "    (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
    "\n",
    "    (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
    "\n",
    "    (\"She runs in the park\", \"Elle court dans le parc\"),\n",
    "\n",
    "    (\"We travel by train\", \"Nous voyageons en train\"),\n",
    "\n",
    "    (\"He writes a letter\", \"Il écrit une lettre\"),\n",
    "\n",
    "    (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
    "\n",
    "    (\"The baby cries\", \"Le bébé pleure\"),\n",
    "\n",
    "    (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
    "\n",
    "    (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
    "\n",
    "    (\"He fixes the car\", \"Il répare la voiture\"),\n",
    "\n",
    "    (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
    "\n",
    "    (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
    "\n",
    "    (\"She dances at the party\", \"Elle danse à la fête\"),\n",
    "\n",
    "    (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
    "\n",
    "    (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
    "\n",
    "    (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
    "\n",
    "    (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
    "\n",
    "    (\"She sings a song\", \"Elle chante une chanson\"),\n",
    "\n",
    "    (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
    "\n",
    "    (\"He sleeps deeply\", \"Il dort profondément\"),\n",
    "\n",
    "    (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
    "\n",
    "    (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
    "\n",
    "    (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
    "\n",
    "    (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
    "\n",
    "    (\"He waits for the bus\", \"Il attend le bus\"),\n",
    "\n",
    "    (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
    "\n",
    "    (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
    "\n",
    "    (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
    "\n",
    "    (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
    "\n",
    "    (\"He studies history\", \"Il étudie l'histoire\"),\n",
    "\n",
    "    (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
    "\n",
    "    (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
    "\n",
    "    (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
    "\n",
    "    (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
    "\n",
    "    (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
    "\n",
    "    (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
    "\n",
    "    (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
    "\n",
    "    (\"She paints a picture\", \"Elle peint un tableau\"),\n",
    "\n",
    "    (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
    "\n",
    "    (\"He sings in the choir\", \"Il chante dans le chœur\")\n",
    "\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T03:40:17.430664600Z",
     "start_time": "2024-04-09T03:40:17.394659400Z"
    }
   },
   "id": "8138d9d94ad873b",
   "execution_count": 157
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.3959, Val Loss: 1.4786\n",
      "Epoch 2, Train Loss: 1.7821, Val Loss: 1.4709\n",
      "Epoch 3, Train Loss: 1.5431, Val Loss: 1.8817\n",
      "Epoch 4, Train Loss: 1.7370, Val Loss: 2.1978\n",
      "Epoch 5, Train Loss: 1.6721, Val Loss: 1.5756\n",
      "Epoch 6, Train Loss: 1.6437, Val Loss: 1.9665\n",
      "Epoch 7, Train Loss: 1.6920, Val Loss: 2.0335\n",
      "Epoch 8, Train Loss: 1.6638, Val Loss: 1.7629\n",
      "Epoch 9, Train Loss: 1.6400, Val Loss: 2.0676\n",
      "Epoch 10, Train Loss: 1.6046, Val Loss: 2.6678\n",
      "Epoch 11, Train Loss: 1.5935, Val Loss: 2.3794\n",
      "Epoch 12, Train Loss: 1.5606, Val Loss: 2.2203\n",
      "Epoch 13, Train Loss: 1.4904, Val Loss: 2.5530\n",
      "Epoch 14, Train Loss: 1.4984, Val Loss: 2.6728\n",
      "Epoch 15, Train Loss: 1.5118, Val Loss: 2.5419\n",
      "Epoch 16, Train Loss: 1.4371, Val Loss: 2.6444\n",
      "Epoch 17, Train Loss: 1.3220, Val Loss: 2.6440\n",
      "Epoch 18, Train Loss: 1.3189, Val Loss: 2.7587\n",
      "Epoch 19, Train Loss: 1.3969, Val Loss: 2.8682\n",
      "Epoch 20, Train Loss: 1.2083, Val Loss: 2.7145\n",
      "Epoch 21, Train Loss: 1.1896, Val Loss: 2.8720\n",
      "Epoch 22, Train Loss: 1.0807, Val Loss: 2.8196\n",
      "Epoch 23, Train Loss: 1.1229, Val Loss: 3.2541\n",
      "Epoch 24, Train Loss: 1.1053, Val Loss: 3.0152\n",
      "Epoch 25, Train Loss: 1.0052, Val Loss: 3.0979\n",
      "Epoch 26, Train Loss: 1.0271, Val Loss: 3.2071\n",
      "Epoch 27, Train Loss: 0.8654, Val Loss: 3.2583\n",
      "Epoch 28, Train Loss: 0.9267, Val Loss: 3.1746\n",
      "Epoch 29, Train Loss: 0.8685, Val Loss: 3.4609\n",
      "Epoch 30, Train Loss: 0.8173, Val Loss: 3.5140\n",
      "Epoch 31, Train Loss: 0.7382, Val Loss: 3.4045\n",
      "Epoch 32, Train Loss: 0.6394, Val Loss: 3.5900\n",
      "Epoch 33, Train Loss: 0.7076, Val Loss: 3.5198\n",
      "Epoch 34, Train Loss: 0.6801, Val Loss: 3.5592\n",
      "Epoch 35, Train Loss: 0.6573, Val Loss: 3.6131\n",
      "Epoch 36, Train Loss: 0.5027, Val Loss: 3.7910\n",
      "Epoch 37, Train Loss: 0.4220, Val Loss: 3.5147\n",
      "Epoch 38, Train Loss: 0.4444, Val Loss: 3.6372\n",
      "Epoch 39, Train Loss: 0.4831, Val Loss: 3.7577\n",
      "Epoch 40, Train Loss: 0.3886, Val Loss: 3.6185\n",
      "Epoch 41, Train Loss: 0.3856, Val Loss: 3.6429\n",
      "Epoch 42, Train Loss: 0.3010, Val Loss: 3.7053\n",
      "Epoch 43, Train Loss: 0.2726, Val Loss: 3.9282\n",
      "Epoch 44, Train Loss: 0.2546, Val Loss: 3.9594\n",
      "Epoch 45, Train Loss: 0.2283, Val Loss: 3.9835\n",
      "Epoch 46, Train Loss: 0.1934, Val Loss: 3.8470\n",
      "Epoch 47, Train Loss: 0.1868, Val Loss: 4.1927\n",
      "Epoch 48, Train Loss: 0.1571, Val Loss: 4.1676\n",
      "Epoch 49, Train Loss: 0.1362, Val Loss: 4.0610\n",
      "Epoch 50, Train Loss: 0.1320, Val Loss: 4.0511\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x400 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAGJCAYAAAC90mOkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACQ50lEQVR4nOzdd3hU1dbH8e+k95AESAIJPfReBaQJShcQUbEAClZQsYsFBb2ir3otcBVsoCKKKKAi0gkgIL33mlASAqSRnszM+8cJA5GQRpJJ4Pd5nnlyzp59zlkTo2Zl7722yWq1WhEREREREZGrcrB3ACIiIiIiImWdEicREREREZF8KHESERERERHJhxInERERERGRfChxEhERERERyYcSJxERERERkXwocRIREREREcmHEicREREREZF8KHESERERERHJhxInEZEyaMSIEdSoUaNI17755puYTKbiDaiMOX78OCaTiRkzZpT6s00mE2+++abtfMaMGZhMJo4fP57vtTVq1GDEiBHFGs+1/KyIiEjBKXESESkEk8lUoFd4eLi9Q73hPfXUU5hMJg4fPnzVPq+++iomk4mdO3eWYmSFd/r0ad588022b99u71BsLiavH3zwgb1DEREpFU72DkBEpDz5/vvvc5x/9913LF269Ir2Bg0aXNNzvvzySywWS5Gufe2113j55Zev6fnXg/vuu4/Jkycza9Ysxo8fn2ufH3/8kSZNmtC0adMiP+eBBx7gnnvuwdXVtcj3yM/p06eZMGECNWrUoHnz5jneu5afFRERKTglTiIihXD//ffnOP/nn39YunTpFe3/lpKSgoeHR4Gf4+zsXKT4AJycnHBy0n/e27VrR506dfjxxx9zTZzWr1/PsWPHePfdd6/pOY6Ojjg6Ol7TPa7FtfysiIhIwWmqnohIMevatSuNGzdmy5YtdO7cGQ8PD1555RUAfvvtN/r27UuVKlVwdXWldu3avPXWW5jN5hz3+Pe6lcunRX3xxRfUrl0bV1dX2rRpw6ZNm3Jcm9saJ5PJxJgxY5g/fz6NGzfG1dWVRo0asWjRoiviDw8Pp3Xr1ri5uVG7dm2mTZtW4HVTa9asYciQIVSrVg1XV1dCQ0N55plnSE1NveLzeXl5cerUKQYOHIiXlxeVKlXi+eefv+J7ER8fz4gRI/D19aVChQoMHz6c+Pj4fGMBY9Rp//79bN269Yr3Zs2ahclkYujQoWRkZDB+/HhatWqFr68vnp6edOrUiZUrV+b7jNzWOFmtVt5++21CQkLw8PCgW7du7Nmz54prY2Njef7552nSpAleXl74+PjQu3dvduzYYesTHh5OmzZtAHjwwQdt00Evru/KbY1TcnIyzz33HKGhobi6ulKvXj0++OADrFZrjn6F+bkoqpiYGEaOHElgYCBubm40a9aMb7/99op+P/30E61atcLb2xsfHx+aNGnCJ598Yns/MzOTCRMmEBYWhpubGwEBAdx8880sXbq02GIVEcmL/iQpIlICzp8/T+/evbnnnnu4//77CQwMBIxfsr28vHj22Wfx8vJixYoVjB8/nsTERN5///187ztr1iwuXLjAo48+islk4v/+7/+44447OHr0aL4jD3///Tdz587liSeewNvbm08//ZTBgwcTGRlJQEAAANu2baNXr14EBwczYcIEzGYzEydOpFKlSgX63HPmzCElJYXHH3+cgIAANm7cyOTJkzl58iRz5szJ0ddsNtOzZ0/atWvHBx98wLJly/jwww+pXbs2jz/+OGAkIAMGDODvv//mscceo0GDBsybN4/hw4cXKJ777ruPCRMmMGvWLFq2bJnj2T///DOdOnWiWrVqnDt3jq+++oqhQ4fy8MMPc+HCBb7++mt69uzJxo0br5gel5/x48fz9ttv06dPH/r06cPWrVu57bbbyMjIyNHv6NGjzJ8/nyFDhlCzZk3OnDnDtGnT6NKlC3v37qVKlSo0aNCAiRMnMn78eB555BE6deoEQIcOHXJ9ttVq5fbbb2flypWMHDmS5s2bs3jxYl544QVOnTrFRx99lKN/QX4uiio1NZWuXbty+PBhxowZQ82aNZkzZw4jRowgPj6ep59+GoClS5cydOhQunfvznvvvQfAvn37WLt2ra3Pm2++yaRJkxg1ahRt27YlMTGRzZs3s3XrVm699dZrilNEpECsIiJSZKNHj7b++z+lXbp0sQLWqVOnXtE/JSXlirZHH33U6uHhYU1LS7O1DR8+3Fq9enXb+bFjx6yANSAgwBobG2tr/+2336yA9Y8//rC1vfHGG1fEBFhdXFyshw8ftrXt2LHDClgnT55sa+vfv7/Vw8PDeurUKVvboUOHrE5OTlfcMze5fb5JkyZZTSaTNSIiIsfnA6wTJ07M0bdFixbWVq1a2c7nz59vBaz/93//Z2vLysqydurUyQpYp0+fnm9Mbdq0sYaEhFjNZrOtbdGiRVbAOm3aNNs909PTc1wXFxdnDQwMtD700EM52gHrG2+8YTufPn26FbAeO3bMarVarTExMVYXFxdr3759rRaLxdbvlVdesQLW4cOH29rS0tJyxGW1Gv+sXV1dc3xvNm3adNXP+++flYvfs7fffjtHvzvvvNNqMply/AwU9OciNxd/Jt9///2r9vn444+tgHXmzJm2toyMDGv79u2tXl5e1sTERKvVarU+/fTTVh8fH2tWVtZV79WsWTNr375984xJRKQkaaqeiEgJcHV15cEHH7yi3d3d3XZ84cIFzp07R6dOnUhJSWH//v353vfuu+/Gz8/Pdn5x9OHo0aP5XtujRw9q165tO2/atCk+Pj62a81mM8uWLWPgwIFUqVLF1q9OnTr07t073/tDzs+XnJzMuXPn6NChA1arlW3btl3R/7HHHstx3qlTpxyfZeHChTg5OdlGoMBYU/Tkk08WKB4w1qWdPHmS1atX29pmzZqFi4sLQ4YMsd3TxcUFAIvFQmxsLFlZWbRu3TrXaX55WbZsGRkZGTz55JM5pjeOHTv2ir6urq44OBj/KzabzZw/fx4vLy/q1atX6OdetHDhQhwdHXnqqadytD/33HNYrVb++uuvHO35/Vxci4ULFxIUFMTQoUNtbc7Ozjz11FMkJSWxatUqACpUqEBycnKe0+4qVKjAnj17OHTo0DXHJSJSFEqcRERKQNWqVW2/iF9uz549DBo0CF9fX3x8fKhUqZKtsERCQkK+961WrVqO84tJVFxcXKGvvXj9xWtjYmJITU2lTp06V/TLrS03kZGRjBgxAn9/f9u6pS5dugBXfj43N7crpgBeHg9AREQEwcHBeHl55ehXr169AsUDcM899+Do6MisWbMASEtLY968efTu3TtHEvrtt9/StGlT2/qZSpUq8eeffxbon8vlIiIiAAgLC8vRXqlSpRzPAyNJ++ijjwgLC8PV1ZWKFStSqVIldu7cWejnXv78KlWq4O3tnaP9YqXHi/FdlN/PxbWIiIggLCzMlhxeLZYnnniCunXr0rt3b0JCQnjooYeuWGc1ceJE4uPjqVu3Lk2aNOGFF14o82XkReT6osRJRKQEXD7yclF8fDxdunRhx44dTJw4kT/++IOlS5fa1nQUpKT01aq3Wf+16L+4ry0Is9nMrbfeyp9//slLL73E/PnzWbp0qa2Iwb8/X2lVoqtcuTK33norv/76K5mZmfzxxx9cuHCB++67z9Zn5syZjBgxgtq1a/P111+zaNEili5dyi233FKipb7feecdnn32WTp37szMmTNZvHgxS5cupVGjRqVWYrykfy4KonLlymzfvp3ff//dtj6rd+/eOdayde7cmSNHjvDNN9/QuHFjvvrqK1q2bMlXX31VanGKyI1NxSFEREpJeHg458+fZ+7cuXTu3NnWfuzYMTtGdUnlypVxc3PLdcPYvDaRvWjXrl0cPHiQb7/9lmHDhtnar6XqWfXq1Vm+fDlJSUk5Rp0OHDhQqPvcd999LFq0iL/++otZs2bh4+ND//79be//8ssv1KpVi7lz5+aYXvfGG28UKWaAQ4cOUatWLVv72bNnrxjF+eWXX+jWrRtff/11jvb4+HgqVqxoOy9IRcPLn79s2TIuXLiQY9Tp4lTQi/GVhurVq7Nz504sFkuOUafcYnFxcaF///70798fi8XCE088wbRp03j99ddtI57+/v48+OCDPPjggyQlJdG5c2fefPNNRo0aVWqfSURuXBpxEhEpJRf/sn/5X/IzMjL47LPP7BVSDo6OjvTo0YP58+dz+vRpW/vhw4evWBdztesh5+ezWq05SkoXVp8+fcjKyuLzzz+3tZnNZiZPnlyo+wwcOBAPDw8+++wz/vrrL+644w7c3NzyjH3Dhg2sX7++0DH36NEDZ2dnJk+enON+H3/88RV9HR0drxjZmTNnDqdOncrR5unpCVCgMux9+vTBbDYzZcqUHO0fffQRJpOpwOvVikOfPn2Ijo5m9uzZtrasrCwmT56Ml5eXbRrn+fPnc1zn4OBg25Q4PT091z5eXl7UqVPH9r6ISEnTiJOISCnp0KEDfn5+DB8+nKeeegqTycT3339fqlOi8vPmm2+yZMkSOnbsyOOPP277Bbxx48Zs3749z2vr169P7dq1ef755zl16hQ+Pj78+uuv17RWpn///nTs2JGXX36Z48eP07BhQ+bOnVvo9T9eXl4MHDjQts7p8ml6AP369WPu3LkMGjSIvn37cuzYMaZOnUrDhg1JSkoq1LMu7kc1adIk+vXrR58+fdi2bRt//fVXjlGki8+dOHEiDz74IB06dGDXrl388MMPOUaqAGrXrk2FChWYOnUq3t7eeHp60q5dO2rWrHnF8/v370+3bt149dVXOX78OM2aNWPJkiX89ttvjB07NkchiOKwfPly0tLSrmgfOHAgjzzyCNOmTWPEiBFs2bKFGjVq8Msvv7B27Vo+/vhj24jYqFGjiI2N5ZZbbiEkJISIiAgmT55M8+bNbeuhGjZsSNeuXWnVqhX+/v5s3ryZX375hTFjxhTr5xERuRolTiIipSQgIIAFCxbw3HPP8dprr+Hn58f9999P9+7d6dmzp73DA6BVq1b89ddfPP/887z++uuEhoYyceJE9u3bl2/VP2dnZ/744w+eeuopJk2ahJubG4MGDWLMmDE0a9asSPE4ODjw+++/M3bsWGbOnInJZOL222/nww8/pEWLFoW613333cesWbMIDg7mlltuyfHeiBEjiI6OZtq0aSxevJiGDRsyc+ZM5syZQ3h4eKHjfvvtt3Fzc2Pq1KmsXLmSdu3asWTJEvr27Zuj3yuvvEJycjKzZs1i9uzZtGzZkj///JOXX345Rz9nZ2e+/fZbxo0bx2OPPUZWVhbTp0/PNXG6+D0bP348s2fPZvr06dSoUYP333+f5557rtCfJT+LFi3KdcPcGjVq0LhxY8LDw3n55Zf59ttvSUxMpF69ekyfPp0RI0bY+t5///188cUXfPbZZ8THxxMUFMTdd9/Nm2++aZvi99RTT/H777+zZMkS0tPTqV69Om+//TYvvPBCsX8mEZHcmKxl6U+dIiJSJg0cOFCloEVE5IamNU4iIpJDampqjvNDhw6xcOFCunbtap+AREREygCNOImISA7BwcGMGDGCWrVqERERweeff056ejrbtm27Ym8iERGRG4XWOImISA69evXixx9/JDo6GldXV9q3b88777yjpElERG5oGnESERERERHJh9Y4iYiIiIiI5EOJk4iIiIiISD5uuDVOFouF06dP4+3tjclksnc4IiIiIiJiJ1arlQsXLlClShXbvnFXc8MlTqdPnyY0NNTeYYiIiIiISBlx4sQJQkJC8uxzwyVO3t7egPHN8fHxsXM0IiIiIiJiL4mJiYSGhtpyhLzccInTxel5Pj4+SpxERERERKRAS3hUHEJERERERCQfSpxERERERETyocRJREREREQkHzfcGqeCsFqtZGVlYTab7R2KXGccHR1xcnJSKXwRERGRckaJ079kZGQQFRVFSkqKvUOR65SHhwfBwcG4uLjYOxQRERERKSAlTpexWCwcO3YMR0dHqlSpgouLi0YGpNhYrVYyMjI4e/Ysx44dIywsLN+N1kRERESkbFDidJmMjAwsFguhoaF4eHjYOxy5Drm7u+Ps7ExERAQZGRm4ubnZOyQRERERKQD9uTsXGgWQkqSfLxEREZHyR7/BiYiIiIiI5ENT9UREREREyruYfZB0BnxDwTcEnFztHdF1R4mTXFWNGjUYO3YsY8eOLVD/8PBwunXrRlxcHBUqVCjR2EREREQkW9RO+LIbWLKyG0zgFQgVQo1E6uLXy4/dfOwacnmkxOk6kF/lvzfeeIM333yz0PfdtGkTnp6eBe7foUMHoqKi8PX1LfSzCkMJmoiIiEg2iwUWPm8kTe7+kJkKWamQFG28Tm7K/To3X/CtZiRSFcOg9Ujwq166sZczSpyuA1FRUbbj2bNnM378eA4cOGBr8/Lysh1brVbMZjNOTvn/o69UqVKh4nBxcSEoKKhQ14iIiIjINdjxI5zYAM6e8Njf4FMFUs5DfCQknID4Ezm/JpyA1DhIS4C0XXBmFxwA1n8GLR+ATs+Db1V7f6oyScUh8mG1WknJyLLLy2q1FijGoKAg28vX1xeTyWQ7379/P97e3vz111+0atUKV1dX/v77b44cOcKAAQMIDAzEy8uLNm3asGzZshz3rVGjBh9//LHt3GQy8dVXXzFo0CA8PDwICwvj999/t70fHh6OyWQiPj4egBkzZlChQgUWL15MgwYN8PLyolevXjkSvaysLJ566ikqVKhAQEAAL730EsOHD2fgwIFF/mcWFxfHsGHD8PPzw8PDg969e3Po0CHb+xEREfTv3x8/Pz88PT1p1KgRCxcutF173333UalSJdzd3QkLC2P69OlFjkVERESkxKTGwdLxxnHXl4yEx2QCz4pQtSU0HAAdxkDv92DoLHhsDbx0HMadhCf+gXvnQN8PoVZXsGTC5m/g0+aw8EW4EG3HD1Y2acQpH6mZZhqOX2yXZ++d2BMPl+L5R/Tyyy/zwQcfUKtWLfz8/Dhx4gR9+vThP//5D66urnz33Xf079+fAwcOUK1ataveZ8KECfzf//0f77//PpMnT+a+++4jIiICf3//XPunpKTwwQcf8P333+Pg4MD999/P888/zw8//ADAe++9xw8//MD06dNp0KABn3zyCfPnz6dbt25F/qwjRozg0KFD/P777/j4+PDSSy/Rp08f9u7di7OzM6NHjyYjI4PVq1fj6enJ3r17baNyr7/+Onv37uWvv/6iYsWKHD58mNTU1CLHIiIiIlJiVrwNKeegUn246YmCX+fqDZUbGC+ANqPg+N+w8h2IWAsbp8HW76DNSLj5GSMREyVON4qJEydy66232s79/f1p1qyZ7fytt95i3rx5/P7774wZM+aq9xkxYgRDhw4F4J133uHTTz9l48aN9OrVK9f+mZmZTJ06ldq1awMwZswYJk6caHt/8uTJjBs3jkGDBgEwZcoU2+hPUVxMmNauXUuHDh0A+OGHHwgNDWX+/PkMGTKEyMhIBg8eTJMmTQCoVauW7frIyEhatGhB69atAWPUTURERKTMOb0NNn1tHPf5ABydr+1+NW6GEX/C0XBY+R9jbdT6KbB5OrR7FDo8CR65/6H8RqHEKR/uzo7sndjTbs8uLhcTgYuSkpJ48803+fPPP4mKiiIrK4vU1FQiIyPzvE/Tpk1tx56envj4+BATE3PV/h4eHrakCSA4ONjWPyEhgTNnztC2bVvb+46OjrRq1QqLxVKoz3fRvn37cHJyol27dra2gIAA6tWrx759+wB46qmnePzxx1myZAk9evRg8ODBts/1+OOPM3jwYLZu3cptt93GwIEDbQmYiIiISJlgscCfzwFWaDIEanYqnvuaTFC7mzF17/AyI4E6vQ3+/i9s/BLaP2GMbLlXKJ7nlTNa45QPk8mEh4uTXV75VcsrjH9Xx3v++eeZN28e77zzDmvWrGH79u00adKEjIyMPO/j7JzzrxkmkynPJCe3/gVdu1VSRo0axdGjR3nggQfYtWsXrVu3ZvLkyQD07t2biIgInnnmGU6fPk337t15/vnn7RqviIiISA7bvodTW8DFG259q/jvbzJB2K3w8Eq4ZxYENoaMC7DqPfikKax6H9IvFP9zyzglTjeotWvXMmLECAYNGkSTJk0ICgri+PHjpRqDr68vgYGBbNp0qUym2Wxm69atRb5ngwYNyMrKYsOGDba28+fPc+DAARo2bGhrCw0N5bHHHmPu3Lk899xzfPnll7b3KlWqxPDhw5k5cyYff/wxX3zxRZHjERERESlWKbGw7E3juNs48AkuuWeZTFC/Lzy6BoZ8a6ylSkuAlW/Dx03h74+NBO7sAUg4BanxYM7K767llqbq3aDCwsKYO3cu/fv3x2Qy8frrrxd5ety1ePLJJ5k0aRJ16tShfv36TJ48mbi4uAKNtu3atQtvb2/buclkolmzZgwYMICHH36YadOm4e3tzcsvv0zVqlUZMGAAAGPHjqV3797UrVuXuLg4Vq5cSYMGxuLI8ePH06pVKxo1akR6ejoLFiywvSciIiJid8snQGosVG4EbR8tnWc6OECjgdCgP+yZB+GT4PxhWPZG7v0dXcHFE1y8wNUr+zj7/PLjTs+Cu1/pfIZiUGZGnN59911MJhNjx47Ns9+cOXOoX78+bm5uNGnS5JoKCdzI/vvf/+Ln50eHDh3o378/PXv2pGXLlqUex0svvcTQoUMZNmwY7du3x8vLi549e+Lm5pbvtZ07d6ZFixa2V6tWrQCYPn06rVq1ol+/frRv3x6r1crChQtt0wbNZjOjR4+mQYMG9OrVi7p16/LZZ58Bxl5U48aNo2nTpnTu3BlHR0d++umnkvsGiIiIiBTUyS2w5VvjuO8H4FjKYyAOjtDkTnhiAwz8HKq0BN9QcKsADpfFYk43kruESIjZaxSaOBoO+xfAztlG2fN1n4I5s3Tjv0Ymq70XnACbNm3irrvuwsfHh27duuXYO+hy69ato3PnzkyaNIl+/foxa9Ys3nvvPbZu3Urjxo0L9KzExER8fX1JSEjAx8cnx3tpaWkcO3aMmjVrFugXdyl+FouFBg0acNddd/HWWyUwZ7cM0M+ZiIiIFJrFDF/eAlHbodlQGDTV3hFdKSsDMpIgIzn7lXTleXrSpeNbXgNnd7uGnFdu8G92n6qXlJTEfffdx5dffsnbb7+dZ99PPvmEXr168cILLwBGCe2lS5cyZcoUpk4tgz88kq+IiAiWLFlCly5dSE9PZ8qUKRw7dox7773X3qGJiIiIlB1bZhhJk6sP3Doxv9724eQCTv7Xbdlyu0/VGz16NH379qVHjx759l2/fv0V/Xr27Mn69euvek16ejqJiYk5XlJ2ODg4MGPGDNq0aUPHjh3ZtWsXy5Yt07oiERERkYuSz8Hy7GTpltfAq7J947lB2XXE6aeffmLr1q05qqrlJTo6msDAwBxtgYGBREdHX/WaSZMmMWHChGuKU0pOaGgoa9eutXcYIiIiIoWTlQ6JpyHhJCSegoQTxnHCKeOrmy/cOgGq3XTtz1r2BqTFQ1ATaD3y2u8nRWK3xOnEiRM8/fTTLF26tETXeYwbN45nn33Wdp6YmEhoaGiJPU9ERERErgNpCXD+yL8SohPZSdJJSDqT/z2+6QXtHoVbXjeqyxVF5AbYNtM47vvf0i8IITZ2+85v2bKFmJiYHJXczGYzq1evZsqUKaSnp+Po6JjjmqCgIM6cyflDeubMGYKCgq76HFdXV1xdXYs3eBEREREp/7LSIe64UVr74utc9tfkmPyvd3ID3xDj5RNy2XEV2DPXSHg2TIUDC+H2yVCra+HiM2fBwueM4xb3Q2jbwn5CKUZ2S5y6d+/Orl27crQ9+OCD1K9fn5deeumKpAmgffv2LF++PEfJ8qVLl9K+ffuSDldEREREyqvE08YmrecPG6NIF5Ok+Aiw5rGPpWdl8KsBvlWzk6JQ8Lns2MPf2CQ2N3W6Q6M74I+nIT4SvhsALYfBbW8b0/gKYvM3EL3LKPfdQ0tP7M1uiZO3t/cVJcQ9PT0JCAiwtQ8bNoyqVasyadIkAJ5++mm6dOnChx9+SN++ffnpp5/YvHkzX3zxRanHLyIiIiJlnNUKf70IG/P4XdHFCwJqQ0AYBNTJftU2XgVNcK6mTnd4Yj0smwCbvoSt38GhZdDvI6jXK+9rk2JgRXbF6e7jwbPitcUi16xMT5KMjIzEweFS4b8OHTowa9YsXnvtNV555RXCwsKYP39+gfdwEhEREZEbyLI3spMm07+SojpQMTtR8gq8+qhRcXD1NjarbTQIfh8DsUfhx7uhyV3Q+72rl+5eOh7SEyC4ObQaUXLxSYGViQ1wS5M2wBV708+ZiIhIKVjzX1iePb3t9snGNDl7y0iB8Hdg/f+MKYKelaDPB9BoYM5+Eetgem/ABKOWQ0gre0R7QyjMBrh238dJyo6uXbvmWD9Wo0YNPv744zyvMZlMzJ8//5qfXVz3EREREWHTV5eSptveLhtJE4CLhxHPyGVQqQEkn4U5w2H2A3AhuwCaORP+zC4I0Wq4kqYyRInTdaB///706pX7PNk1a9ZgMpnYuXNnoe+7adMmHnnkkWsNL4c333yT5s2bX9EeFRVF7969i/VZ/zZjxgwqVKhQos8QERERO9s5B/583jju/AJ0eNK+8eQmpBU8ugo6vwgOTrDvd/hfW9jxkzG1MGYvuPtD9zfsHalcpkyvcZKCGTlyJIMHD+bkyZOEhITkeG/69Om0bt2apk2bFvq+lSpVKq4Q85VXSXkRERGRAjmwCOY9Clih7SPQ7VV7R3R1Tq5wy6vQ8HaY/wRE78yOPXu9VY83r77+SexCI075sVohI9k+rwIuP+vXrx+VKlVixowZOdqTkpKYM2cOI0eO5Pz58wwdOpSqVavi4eFBkyZN+PHHH/O877+n6h06dIjOnTvj5uZGw4YNWbp06RXXvPTSS9StWxcPDw9q1arF66+/TmZmJmCM+EyYMIEdO3ZgMpkwmUy2mP89VW/Xrl3ccsstuLu7ExAQwCOPPEJSUpLt/REjRjBw4EA++OADgoODCQgIYPTo0bZnFUVkZCQDBgzAy8sLHx8f7rrrrhz7hu3YsYNu3brh7e2Nj48PrVq1YvPmzQBERETQv39//Pz88PT0pFGjRixcuLDIsYiIiEghHVtjTHuzmqHp3dDrvZIt+lBcgprAwyuMynmOLoAVqraCFg/YOzL5F4045SczBd6pYp9nv3IaXDzz7ebk5MSwYcOYMWMGr776Kqbs/0jMmTMHs9nM0KFDSUpKolWrVrz00kv4+Pjw559/8sADD1C7dm3ats1/MzWLxcIdd9xBYGAgGzZsICEhIcd6qIu8vb2ZMWMGVapUYdeuXTz88MN4e3vz4osvcvfdd7N7924WLVrEsmXLAPD1vbLMZ3JyMj179qR9+/Zs2rSJmJgYRo0axZgxY3IkhytXriQ4OJiVK1dy+PBh7r77bpo3b87DDz+c7+fJ7fNdTJpWrVpFVlYWo0eP5u677yY8PByA++67jxYtWvD555/j6OjI9u3bcXZ2BmD06NFkZGSwevVqPD092bt3L15eRdwhXERERArn1Fb48R7ISoN6fWDA/8ChHI0PODpDp+egfj/Y/auxJqs8xX+DUOJ0nXjooYd4//33WbVqFV27dgWMaXqDBw/G19cXX19fnn/+eVv/J598ksWLF/Pzzz8XKHFatmwZ+/fvZ/HixVSpYiSS77zzzhXrkl577TXbcY0aNXj++ef56aefePHFF3F3d8fLywsnJ6c8p+bNmjWLtLQ0vvvuOzw9jcRxypQp9O/fn/fee4/AwEAA/Pz8mDJlCo6OjtSvX5++ffuyfPnyIiVOy5cvZ9euXRw7dozQ0FAAvvvuOxo1asSmTZto06YNkZGRvPDCC9SvXx+AsLAw2/WRkZEMHjyYJk2aAFCrVq1CxyAiIiJFELMfZg6GjCSo0QnunG4kIuVRpXrQ7RV7RyFXocQpP84exsiPvZ5dQPXr16dDhw588803dO3alcOHD7NmzRomTpwIgNls5p133uHnn3/m1KlTZGRkkJ6ejodHwZ6xb98+QkNDbUkTQPv27a/oN3v2bD799FOOHDlCUlISWVlZ+ZZ2zO1ZzZo1syVNAB07dsRisXDgwAFb4tSoUSMcHR1tfYKDg9m1a1ehnnX5M0NDQ21JE0DDhg2pUKEC+/bto02bNjz77LOMGjWK77//nh49ejBkyBBq164NwFNPPcXjjz/OkiVL6NGjB4MHDy7SujIRESnn0hLgn8+hZheofuX/J6WYxR2H7wdCaixUaQlDfwRnbfUhJUNjgPkxmYzpcvZ4FXJe7siRI/n111+5cOEC06dPp3bt2nTp0gWA999/n08++YSXXnqJlStXsn37dnr27ElGRkaxfavWr1/PfffdR58+fViwYAHbtm3j1VdfLdZnXO7iNLmLTCYTFoulRJ4FRkXAPXv20LdvX1asWEHDhg2ZN28eAKNGjeLo0aM88MAD7Nq1i9atWzN58uQSi0VERMqguAj4uieET4KZdxgjIVJyLkTDdwPhQhRUqg/3/2psNitSQpQ4XUfuuusuHBwcmDVrFt999x0PPfSQbb3T2rVrGTBgAPfffz/NmjWjVq1aHDx4sMD3btCgASdOnCAqKsrW9s8//+Tos27dOqpXr86rr75K69atCQsLIyIiIkcfFxcXzGZzvs/asWMHycnJtra1a9fi4OBAvXr1ChxzYVz8fCdOnLC17d27l/j4eBo2bGhrq1u3Ls888wxLlizhjjvuYPr06bb3QkNDeeyxx5g7dy7PPfccX375ZYnEKiIiZdDJzfBVdzi7zzjPTDEKFWQk532dvZ3eBvGR9o6i8FJi4ftBEHcMKlSHB+arAp2UOCVO1xEvLy/uvvtuxo0bR1RUFCNGjLC9FxYWxtKlS1m3bh379u3j0UcfzVExLj89evSgbt26DB8+nB07drBmzRpefTVnic+wsDAiIyP56aefOHLkCJ9++qltROaiGjVqcOzYMbZv3865c+dIT0+/4ln33Xcfbm5uDB8+nN27d7Ny5UqefPJJHnjgAds0vaIym81s3749x2vfvn306NGDJk2acN9997F161Y2btzIsGHD6NKlC61btyY1NZUxY8YQHh5OREQEa9euZdOmTTRo0ACAsWPHsnjxYo4dO8bWrVtZuXKl7T0REbnO7ZkHM/oam5kGNoFHwsErEM7uv7SfUFlz/gj8OBS+6AqTW8PaT8CS9x82y4z0JPhhiLHXkVcQDPsNfILtHZXcAJQ4XWdGjhxJXFwcPXv2zLEe6bXXXqNly5b07NmTrl27EhQUxMCBAwt8XwcHB+bNm0dqaipt27Zl1KhR/Oc//8nR5/bbb+eZZ55hzJgxNG/enHXr1vH666/n6DN48GB69epFt27dqFSpUq4l0T08PFi8eDGxsbG0adOGO++8k+7duzNlypTCfTNykZSURIsWLXK8+vfvj8lk4rfffsPPz4/OnTvTo0cPatWqxezZswFwdHTk/PnzDBs2jLp163LXXXfRu3dvJkwwdiU3m82MHj2aBg0a0KtXL+rWrctnn312zfGKiEgZZrXCmg9hzgijmlvdXvDQIqjSAu78BkwOsGMWbJtp70gvSUuEpePhf+3gQPa2GeZ0o+3r2+BswWej2EVmGvx0L5zaDG4V4IF54F/T3lHJDcJktRZws6DrRGJiIr6+viQkJFxRtCAtLY1jx45Rs2ZN3Ny0sFBKhn7ORESuA1kZsOAZ2J6dFLV7HHr+BxwuFS1i9fuw4m1wcoeHl0NgI/vECmCxGEncsgmQHGO01e4OPd8xkpBF4yA9ERyzN2VtPybnZykLzFnG9Mf9C8DZE4b/DiGt7R2VlHN55Qb/phEnERERkcJIiTWKP2yfaYwq9fkAer97ZaJx83NGcpKVCj8Ph/QL9ok3cgN82Q1+G20kTf614d6fjWIKletDi/vhiX+gTo9Lo0/f9Cw7o08ZKbB/oTHStH+BkdwN/VFJk5Q6lSMXERERKajzR2DWXXD+MLh4wZAZEHZr7n0dHOCOL2BqJzh/yBihuuPLQlfNLbKEU7DsDdg1xzh39YEuL0LbR8HJJWdf36pw3y+w/Qdj9OnkJph6s/1GnxJOwsHFcHARHFttTIUEMDnCkOlQq0vpxiOCEicRERGRgolYb4x6pMaCTwjcOxuCGud9jWdF4xf96X2MBKZ6R2j9YMnGmZEC6ybD2o+N6n6YoOUDcMvr4FX56teZTMboU61u8MdTcHiZMfq07w8Y8BlUqltyMVssRoW/g38ZyVL0v/ZlrFAN6vaGpndDSKuSi0MkD0qcRERERPKz82djqps5wyj+MPQn8A4q2LXVboLu443Rn79egqqtILgENkm3Wo0Kf0vHQ0L29hrV2kOvd6FK84Lf5+Lo07aZsPiVy0afXoP2o4tv9Ck9CY6uNBKlg0surb0CwAShbY2CG3V7QeUGpTdSJ3IVSpxycYPVy5BSpp8vEZFyxGqF8Hdh1bvGeYP+MOgLcPEo3H06PAUR6+DQYqPAwSOrwC3vheiFErUD/noZItcZ5z4hcNtb0GhQ0RIOU/YoVe1u8PtTcGQ5LH3dGH0a+BlUDCvc/dISjel3CSch9ogxmnVstZGIXuTiDXVuMUaWwm41RutEyhAlTpdxdnYGICUlBXd3dztHI9erlJQU4NLPm4iIlFGZafD7mEtrhDo+Dd3fNNYuFZaDAwyaCtM6Q+xR+P1JY33UtY6iJJ+HFRNhy7eA1ajgd/Mz0OHJwid3ufENMYpIbPseFr8KJzdeGn266Qlj9MmcBReiLiVGCScuO85+pSfkfn+/GkaiVLenMY3x32uvRMoQlSP/l6ioKOLj46lcuTIeHh6YNCwsxcRqtZKSkkJMTAwVKlQgOFib9YmIlElWq7F57R9j4cQ/4OAEfT+EViOu/d4nNsH0XmDJMqrxtX24aPcxZ8Hmb2Dl25CWnZQ0Hgy3TjSSnZKQcPLS6BMYSY85Cy6cBqsl/+vd/YzYfEMhtB3U6w0V62oKnthVYcqRK3H6F6vVSnR0NPHx8aUfnNwQKlSoQFBQkJJyEZGyJO64MXXs4ivpjNHu6gt3fWtMWSsu6/9nrB1ydIGRS4w1U4VxbI2xVipmj3Ee1AR6vw/V2xdfjFdjtV4afUpPvNTu4GysjfINzU6OLn+Fgk9VcPUq+fhECkmJUx4K+s0xm81kZmaWYmRyI3B2dsbRsYxtKCgiUhqsVtj0FRxZCXVvg/r9wTPAfvEkRsHxNXBslZEoxUfmfN/JDWrcbGwQW6le8T7baoXZ9xt7ElWoDo+uBvcK+V+XcBKWvGYUgABjBOeW142RsNIuF37hjLFxrlegkRx5Vi7aFEYRO1PilIfCfHNERESkGFjMxt5AG6ddajM5GnvxNBoE9fuBh3/JxpASC8f/vpQonfvX5q4OTlC1NdTsbMQV0gacXEsuntQ4mNYF4iOMz3/3zKtPWctMM8qLr/nQ2EzX5ACtH4Jur5b8903kOqfEKQ9KnEREREpRZhrMfRj2/Q5k7xMUtQOid17q4+Bk7B3UaBDU71uw0Ze8ZGUYa5SidxnPiViXvS/Q5b/ymCC4mZEo1exilAwv7alkp7bCNz2NynI9J0H7J3K+b7XCgYVG0hkfYbRV6wC93yuZcuYiNyAlTnlQ4iQiIlJKUmLhp/uMEtmOLjBoGjS+w3jv/BFjytme+XDmss1OHZyhTncjiarXG9x8835GWgJE776UJEXvhJj9YMllun2l+tmJUmejgltZGK3Z8AX89YKRPD60GEJaG+1nD8Kily8VYvCuYpQXbzxYxRREilG5SZw+//xzPv/8c44fPw5Ao0aNGD9+PL179861/4wZM3jwwZy7bbu6upKWllbgZypxEhERKQXxJ2DmYDh3wCiwcM8PULNT7n3PHoS9841EKmbvpXZHF6hza3YS1QvSLxgJUtTOS0lS3PHc7+nmC0FNjcIJVVtBjU7gHVjcn/LaWa0wZ4Tx+X1D4cGFsPEL+Odzo/Keowu0HwOdnlNxBZESUJjcwK77OIWEhPDuu+8SFhaG1Wrl22+/ZcCAAWzbto1GjRrleo2Pjw8HDhywnasymYiISCGlxhnT12KPQr0+EFC7eO8fvQt+GGLs7eNdxdgHKLDh1ftXqgtdXjReMfuNJGL3XCPpOvCn8cJEzql2l/EJMaauBTW5lCxVqFY+RmZMJrj9UyMJjD0KnzS7VNq7bi+jOEVx//MRkSIpc1P1/P39ef/99xk5cuQV782YMYOxY8cWqlR4eno66enptvPExERCQ0M14iQiIjeOtESIXG8URTi+xhixuZiEmByh5QPQ+UWjnPS1OrrKmJ6XcQEqNYD7fynavkJWK8Tsy57ONxfOHzZirVj3yiSpLEy5u1ZRO+GrHmBOB//a0Otdo/qgiJSocjPidDmz2cycOXNITk6mffur70OQlJRE9erVsVgstGzZknfeeeeqo1MAkyZNYsKECSURsoiISNmUkQyR/2SX214Np7eD1ZyzT0AYeFYy1h9tmQHbfzQ2Y7352aKXCd/1C8x7zFhfVP1mY3peUQs9mEzGKFVgQ+j2CiSeAo8AcHYv2v3KuuCmMPx3Y+1XkztLtqKfiBSJ3Uecdu3aRfv27UlLS8PLy4tZs2bRp0+fXPuuX7+eQ4cO0bRpUxISEvjggw9YvXo1e/bsISQk979macRJRESue5mpcGJjdqK0Bk5tubI4gl8NY51Pzc7GV59goz1iPSyfaCRQAC7e0H608XIr4P8nrVajXPbS143zRoOMQhD65V9EyrhyUxwCICMjg8jISBISEvjll1/46quvWLVqFQ0b5jEXOltmZiYNGjRg6NChvPXWWwV6nopDiIjIdcNqhb9eMkaMzOk53/MJya4g18lIlCqE5n2fw8th+YRLZcLd/aHTs9BmVN6jPBYzLH4FNkw1zm8aDbe9rc1QRaRcKFeJ07/16NGD2rVrM23atPw7A0OGDMHJyYkff/yxQP2VOImIyHXjYilrAK+gS0lSzU7gV7PwxREsFtj3G6z4D5w/ZLR5VzGKNrS4Hxydc/bPTIN5j8De34zz2/4DHcZc22cSESlF5XKN00UWiyXH1Lq8mM1mdu3addWpfSIiItet6F2w5DXj+Lb/GFPrrrWKnIND9ia0/WHHjxD+LiSehAVjYd2n0O1VaHSH0S81Dn6815ji5+AMg6Yaa3NERK5Tdk2cxo0bR+/evalWrRoXLlxg1qxZhIeHs3jxYgCGDRtG1apVmTRpEgATJ07kpptuok6dOsTHx/P+++8TERHBqFGj7PkxRERESldGMvzykDE9r26v4kmaLufoZFTaa3oXbP4GVn9glMr+dST8/RF0eAr+/i+c3Q+uPtl7NHUuvueLiJRBdk2cYmJiGDZsGFFRUfj6+tK0aVMWL17MrbfeCkBkZCQOl82RjouL4+GHHyY6Oho/Pz9atWrFunXrCrQeSkRE5Lqx6GU4dxC8g2HAZyW3X5GTK9z0OLR4ADZ8Dms/hTO7jel5YDz//l8h8OrVbUVErhdlbo1TSdMaJxERKdd2/2qMNmEyyleX5khPSiys/QQ2TAP/WnDv7LyLToiIlHHleo2TiIiIXEXccfhjrHHc6bnSnx7n4Q+3ToCuL4OjCzg4lu7zRUTsSImTiIhIeWDOhF9HQXoihLQ1khd7uV43oRURyYM2WRARESkPwifByU3g6guDv7qyNLiIiJQoJU4iIiJl3dFVsOa/xvHtn4BfdfvGIyJyA1LiJCIiUpYln4O5jwBWaDnc2GdJRERKnRInERGRsspqhflPQFI0VKwHvd61d0QiIjcsJU4iIiJl1YapcGgxOLrCnd+Ai4e9IxIRuWEpcRIRESmLonbA0vHGcc//QFBj+8YjInKDUzlyEREpeRYL/PM/qFQfwm61dzTFKysDTm+DiL/h+Fq4EAX1+0LLYVChWtHumZ5kbHJrzoB6faHNqOKNWURECk2Jk4iIlLzdv8CS18DkCPfOLt/JU2YanNpsJEkRf8OJTZCVmrNPzF5Y/YHxOVuNgLCe4FiI/+X+9RKcPwzeVWDAFDCZivUjiIhI4SlxEhGRkmWxwJoPjWOrGeaMgAcXQnAzu4ZVYBkpcHJjdqK0Fk5uBnN6zj4eAVC9A1S/Gdz9YPsPcGwVHFpivLyrQMsHjFEo35C8n7frF9g+EzDB4C/Bw7/EPpqIiBScyWq1Wu0dRGlKTEzE19eXhIQEfHx87B2OiMj1b98fMPt+cPWBoKbGKI1XEIxaBhVC7R1d7iI3wMFFRqJ0aitYMnO+71kZanSE6h2hxs1GxTuHfy0bPn8EtswwkqiU80abyQHCboNWDxqjUQ6OOa+JPQZTO0HGBej8Itzyaol9RBERKVxuoMRJRERKjtUKX3SFqO3Q6Tno8BR80wvO7oPKDeGhReDma+8oLzm1BZa/BUdX5mz3qZqdJGUnSwF1Cj59LivdSB63zIDja3Les+UwaPEA+FYFcyZ809OIIfQmGPFn4ab3iYhIoSlxyoMSJxGRUnR4GcwcDM4eMHYXeFaE+BPwVQ9jb6KaXeC+X8DJxb5xxuyDFW/D/gXGuYOzsdFsrS5GouRXo3jWGZ07DFumw/ZZkBprtJkcoG4vcPWGnbONRPKxv4teWEJERApMiVMelDiJiJSib3pD5Dq46QnoNelSe9QOmN4HMpKg2VAY+Ll9CiDEHoPwd42EBauRxDS9B7q+ZCRLJSUz7dIoVMTfOd+76ztoOKDkni0iIjaFyQ00B0BEREpGxDojaXJ0gQ5P5nwvuBkMmQGz7oYdP0KF6tBtXOnFlhgFq9+Hrd+CJctoa3A7dHsVKtcv+ec7u0HTIcbr7EEjgdr3OzQZoqRJRKSM0oiTiIiUjJmDjal6rUZA/09y77NlBvzxtHE84H/Q4v6SjSklFv7+CDZ+AVlpRlvt7nDLa1C1Zck+W0REyhyNOImIiH2d3mYkTSYH6Dj26v1ajYD4SKNc+R9Pg08VqH1L8ceTfgHWfwbrp0B6otEW2g66jzeq4omIiORDiZOIiBS/i/s2Nb4T/Gvm3feW143kadccmD3MqLQX1Lh44shMhU1fw9//vVQSPLCJkTCF3aqNZUVEpMCUOImISPGK2W8UPgDo9Gz+/U0mY5peYpRRKOGHIcYeT75Vix5DYpSxieymb+DCaaMtoI6xhqnhwCv3XBIREcmHEicRESlef//X+Fq/H1RuULBrnFzhnpnwdU84dwBm3QUP/gVuhViLajHD4eXGuqmDi8BqNtp9QqDry0b1Pu2LJCIiRaT/g4iISPGJPQa7fjGOOz9fuGvd/eC+OcYeT2d2w5zhcO/P4Oic93UJJ2HbTNj6PSSevNRerT20HG7sx+TsVrhYRERE/kWJk4iIFJ+1HxsjPbW7Q5UWhb/erzrcOxtm9IUjK2DBWLh9ypVrkcxZcGiJMbp0eClYLUa7ux80uxdaDiudsuIiInLDsOsk788//5ymTZvi4+ODj48P7du356+//srzmjlz5lC/fn3c3Nxo0qQJCxcuLKVoRUQkT4mnYfss47iwo02Xq9oS7pxuVOTbNhNWf3DpvbgIWPE2fNwYfhoKhxYbSVONTjD4a3h2P/R6R0mTiIgUO7uOOIWEhPDuu+8SFhaG1Wrl22+/ZcCAAWzbto1GjRpd0X/dunUMHTqUSZMm0a9fP2bNmsXAgQPZunUrjRsXUwUmEREpmnVTwJwB1TpA9Q7Xdq96vaDP+/Dnc7DybchMgagdxigU2dsPelSE5vca0/Eq1rnm8EVERPJS5jbA9ff35/3332fkyJFXvHf33XeTnJzMggULbG033XQTzZs3Z+rUqQW6vzbAFREpAcnnjVGgzBS4/1eo06N47rt0PKz91+a5tbpBq+FQry84uRTPc0RE5IZULjfANZvNzJkzh+TkZNq3b59rn/Xr1/PsszlL2/bs2ZP58+df9b7p6emkp6fbzhMTE4slXhERucw/nxlJU3BzY31Tcen+JqQlwtGV0OgOY+1SfvtCiYiIlAC7J067du2iffv2pKWl4eXlxbx582jYsGGufaOjowkMDMzRFhgYSHR09FXvP2nSJCZMmFCsMYuIyGXSEmDjl8Zx5+eLd1NZBwfo/3Hx3U9ERKSI7L4DYL169di+fTsbNmzg8ccfZ/jw4ezdu7fY7j9u3DgSEhJsrxMnThTbvUVEBCNpSk+ASvWN6XMiIiLXIbuPOLm4uFCnjrGot1WrVmzatIlPPvmEadOmXdE3KCiIM2fO5Gg7c+YMQUFBV72/q6srrq6uxRu0iIgYMpKNaXoANz9rjBCJiIhch8rc/+EsFkuONUmXa9++PcuXL8/RtnTp0quuiRIRkRK29TtIOQ9+NaDxYHtHIyIiUmLsOuI0btw4evfuTbVq1bhw4QKzZs0iPDycxYsXAzBs2DCqVq3KpEmTAHj66afp0qULH374IX379uWnn35i8+bNfPHFF/b8GCIiN6asdFj7qXHccSw42n0Sg4iISImx6//lYmJiGDZsGFFRUfj6+tK0aVMWL17MrbfeCkBkZCQOl0376NChA7NmzeK1117jlVdeISwsjPnz52sPJxERe9jxI1w4Dd5VjP2URERErmNlbh+nkqZ9nEREioE5C6a0grjj0HMStH/C3hGJiIgUWmFygzK3xklEREpBWgKcPQgWS9Gu3zPXSJo8AozNaEVERK5zmpAuImJP0btgxX/g1Ba4dULpTHnbPRd+fwoyLoC7H1TvCDU6Qc1OUKlB/pXxLBZY86FxfNMT4OJZ8jGLiIjYmRInERF7OH8EVr4Du3+51Db/cTi6Cvp+AK7exf/MrHRY/Cpsyt6s1uQIqXGwf4HxAnD3hxrZiVSNTsbeTP9OpA78CWf3g6svtH24+OMUEREpg5Q4iYiUpoRTsOo92DYTrGajrdEdEFDbGMXZ+ROc3ARDpkNws+J7buwxmDMCorYb5zc/C11eMka8jq+B439D5D+QGgv7/jBeYEzFu3xEqmK9S6NNbR8GN9/ii1FERKQMU3EIEZHSkHwO/v4INn4J5uy96sJ6wi2vQXBT4zxiPfw6EhJPgaML3PY2tH0ETKZre/a+P2D+aEhPMKbmDfoC6t52ZT9zJpzeZiRSx9bAiQ2QmZKzj1sFSIsHZw8Yuws8K15bbCIiInZUmNxAiZOISElKS4T1U2D9/yAjyWir1gG6j4fquWzenRILv42GAwuN8/r94PbJ4OFf+GdnZcCyN+Cfz4zzkLbGSJZvSMGvP70Njq/OHpHaAFmpxns3jYZe7xQ+JhERkTJEiVMelDiJSKnITDVGl/7+yJj+BhDUFLq/AXW65z2KZLXChmmw9HUwZ4BPCNz5NVS7qeDPj4+EOQ/Cqc3Gefsx0ONNcHQu8kciK8MoYhF3zJhe6OxW9HuJiIiUAUqc8qDESURKlDkTtn0Pq/4PLkQZbQFhxpS8BrfnX7Hucqe3wy8PQuxRo5BDt1fg5mfAwTHv6w4sgnmPGlPq3Hxh4OdQv29RP5GIiMh1S4lTHpQ4iUiJsFiMvY1WvG2MyAD4hkLXl6HpPeBYxFo86RdgwbOw62fjvGYXuONL8A68sq85E5ZPhHWfGudVWhpT8/xqFO3ZIiIi1zklTnlQ4iQixe7Yaljy+qWKdZ6VoNPz0PpBcHK99vtbrbB9Fix83ijW4FkJBk0zpvxdlHAKfnkITvxjnLd9FG57q3ieLyIicp0qTG6gcuQiIkUVsw+WvgGHFhvnLt7Q8Wm46XFw9Sq+55hM0OI+CGltrFuK2QMz7zCm7XV71dj7ad4jkHIeXH2MYhKNBhbf80VEREQjTiIihXYhGlb+J3svJgs4OEGrB419kbwqleyzM1ONTWw3f22cB9QxNtPFCkFNYMi3xp5QIiIiki+NOImIlIT0JGP90LrJl/Y3qt8PekyAinVKJwZnd+j3X6jVBX57Es4fNtpbPwQ9J6nSnYiISAlR4iQikh9zFmz7DlZOguQYoy2kDdz6Vu57MZWGhgMguLlR7rxWV03NExERKWFKnETsLS3RmOrl4mHvSErO2QNwaCk0uRO8g+wdTcFZrXBwkbGO6dwBo82vJvR4AxoOzHsvptLgVx36f2zfGERERG4QSpxE7Cn5PExpDR4B8PByY8+d60lKLIS/C5u+AqvZ2NuoxxvGeqDC7GdkD6e2GpXyIv42zt39jDVMrUeCk4t9YxMREZFSp8RJxJ72zIXUWOO14FkY/JX9RzGKgzkLNn8D4e9AapzR5l0FLpyGP5+FnbOh38cQ2LBknm8xw77f4cSmS225fV9tbaac57HHjOsBHF3hpsfg5mfBvULJxCsiIiJlnhInEXva/etlx78Y+/I0v9d+8RSHw8th8Stwdr9xXrkh9JoENTrBxi9hxVtwYgNM62SU7u78glHwoDiYs4zv6er34fyha79f03vgltegQui130tERETKNZUjF7GX+BPwcWPABG1GwaYvwdkTHl1dehXaitO5w7DkVWNNEIC7P9zyKrQcAY6X/Y0m4SQsfBEO/Gmc+9WEfh9B7W5Ff7Y5E3b+DGs+gNijRptbBWh6t7F2zPafueyvVz3P5uAEjQZBleZFj0lERETKPJUjFykP9sw1vlbvAL3fM0Zojq+BX0fCyKXlZx1NarwxwrNhKliyjKSj7SPQ5UVjXdC/+YbA0FmwbwEsfAHijsH3A40k57b/FG4fpKwM2DEL1nwI8ZFGm0cAtB9jJKNu+uOIiIiIFA8lTiL2susX42vjweDgCHd8AZ93gKjtsGIi3Pa2XcPLl8UMW7+FFW9DynmjLew2I/mpVDf/6xv0g5qdjY1kN0wz1j0dWmKU+G5xf95rvbLSYdv3sOYjSDxptHlWgg5PGfsZuXpd++cTERERuYym6onYw7lDRjU9Byd47iB4Bhjt+/+En7LXON0/11jzVBYdWw2LxsGZ3cZ5xbrG5qthPYp2v1Nb4I+nIXqXcV69o1E84t8JWGYqbPkW1n5iFJoA8AqCm8dCy+HXd0l3ERERKXaaqidS1l0cbarV7VLSBFC/r1HuevPXMO8xeHxd4aaulbS447D4Vdi/wDh384Wur0CbkeDoXPT7Vm0FD4fDhs9h5TsQsRamdjQq2d38jFHKfPN0I2G6uAGtT1XjvRYPgLPbtX4yERERkTxpxEmktFmtxmjT+cMwaBo0uyfn+5mp8EU3OLvPmPp2789lo0R58jn4XztIOQcmB2NKXNdXciZ+xSEuAhY+b0zbA/CvZWwSnHLOOPetBp2eNaoPOrkW77NFRETkhlKY3MCuO1BOmjSJNm3a4O3tTeXKlRk4cCAHDhzI85oZM2ZgMplyvNzc9NdmKUeidhhJk5ObMcL0b87ucOc3xvuHlhhFF8qCxa8ayUvFuvDYWuj7YfEnTQB+1Y1kccgM8Ao0quSlnAO/GnD7FHhqK7R+UEmTiIiIlCq7TtVbtWoVo0ePpk2bNmRlZfHKK69w2223sXfvXjw9Pa96nY+PT44Ey1QW/hovUlC7s6fp1e0Jrt659wlsaBSHWPg8LB1vrPkJblp6Mf7b0XDY+RNggoGfl9zGtReZTEY58FrdjL2fKlQzimg4anaxiIiI2IddfwtZtGhRjvMZM2ZQuXJltmzZQufOna96nclkIigoqEDPSE9PJz093XaemJhYtGBFioPFAruzy5A3vjPvvm1GwZGVxn5HvzwEj64Cl6v/QaHEZKbCgmcuxRTSuvSe7V4BurxQes8TERERuQq7TtX7t4SEBAD8/f3z7JeUlET16tUJDQ1lwIAB7Nmz56p9J02ahK+vr+0VGhparDGLFMqJfyDxFLj6GOuX8mIywe2TwTsYzh+CRS+XToz/tuZDY7qcdzB0f90+MYiIiIjYWZlJnCwWC2PHjqVjx440btz4qv3q1avHN998w2+//cbMmTOxWCx06NCBkydP5tp/3LhxJCQk2F4nTpwoqY8gkr+L1fTq9ytYJTjPAGN/J0yw9TvYM78ko7tSzH74+2PjuPd7RhU9ERERkRtQmVkwMHr0aHbv3s3ff/+dZ7/27dvTvn1723mHDh1o0KAB06ZN46233rqiv6urK66uWkQuZYA5E/bON46bDC74dTU7G2W3//4v/PGUUbq7QimMnFossGAsWDKhbm9ocHvJP1NERESkjCoTI05jxoxhwYIFrFy5kpCQkEJd6+zsTIsWLTh8+HAJRSdSTI6ugpTz4FERanYt3LXdXoGqrSEtAeY+DOaskogwp23fQeR6cPaEPu+XjZLoIiIiInZi18TJarUyZswY5s2bx4oVK6hZs2ah72E2m9m1axfBwcElEKFIMbpYTa/RwMJXh3N0hsFfgYu3kcys+aDYw8shKcao5gdwy6ulM8IlIiIiUobZNXEaPXo0M2fOZNasWXh7exMdHU10dDSpqam2PsOGDWPcuHG284kTJ7JkyRKOHj3K1q1buf/++4mIiGDUqFH2+AgiBZOZCvsWGMf5VdO7Gv+a0O8j43jVexCxvnhiy82iccboVnAzaPtoyT1HREREpJywa+L0+eefk5CQQNeuXQkODra9Zs+ebesTGRlJVFSU7TwuLo6HH36YBg0a0KdPHxITE1m3bh0NG5bwvjIl4Pi5ZKasOMSe0wn2DkVK2qElkHEBfEIgtF3R79N0CDQbClYL/DoKUuOKL8aLDi8zRsdMDtD/E+2dJCIiIoKdi0NYrdZ8+4SHh+c4/+ijj/joo49KKKLS9fGyg8zffprzyRk0qqJqZde1i9X0Gt8BDtf494o+78OJDUaJ8D+ehiHfFt/6o4wUWPCscdz2UajSonjuKyIiIlLOlYniEDeqfk2rALBwVxQWS/5JpJRTaYnGiBNAkyJO07ucq7ex3snBCfb+BvMeg4zka78vwOr/g/gI8KlqrG0SEREREUCJk111qlsRbzcnziSms+l4rL3DkZJyYCFkpUFAGAQ1LZ57Vm0FfT8EkyPs/Am+7A5nD17bPc/sgXWTjeM+7xsJmoiIiIgASpzsytXJkZ6NggBYsDMqn95Sbl2cptfkzuIt6d1qBAz/A7wC4ew++KLrpWcVlsViTPuzZBmb89bvW3xxioiIiFwHlDjZWb+mRhn1v3ZHkWW22DkaKXbJ5+HoSuO4qNX08lKjIzy6Bmp0gsxk+HUk/PkcZKUX7j5bvoGTm4xy573/r/jjFBERESnnipQ4nThxgpMnT9rON27cyNixY/niiy+KLbAbRcc6FfHzcOZcUgYbjmm63nVn73xjFCe4GVSsUzLP8A6EYb9Bp+eN801fwTc9IS6iYNdfiIZlE4zj7q+Db9WSiVNERESkHCtS4nTvvfeycqXxV/To6GhuvfVWNm7cyKuvvsrEiROLNcDrnbOjA70aX5yud9rO0Uix2/2r8bXx4JJ9joOjkfTc9wu4+8HpbTCtMxxYlP+1f70E6YlQpSW00X5oIiIiIrkpUuK0e/du2rZtC8DPP/9M48aNWbduHT/88AMzZswozvhuCBer6/21O5pMTde7fiScgoh1xnGjO0rnmWG3GlP3qraGtHj48W5Y+gaYs3Lvf3CxMSpmcjT2bHJwLJ04RURERMqZIiVOmZmZuLq6ArBs2TJuv/12AOrXr59js1opmHY1/ano5UJ8SiZrD5+zdzhSXPbMBaxQrT1UCC2951YIhQf/gnaPGedrP4bvbjem5F0uIxn+zJ7ed9PjEFxMFf9ERERErkNFSpwaNWrE1KlTWbNmDUuXLqVXr14AnD59moCAgGIN8Ebg5OhA78ZGkQhV17uO2Da9LeFperlxcoHe78GQGUbBh4i1MLUTHFt9qU/4JEiIBN9Q6PZK6ccoIiIiUo4UKXF67733mDZtGl27dmXo0KE0a9YMgN9//902hU8K52J1vcV7oknPMts5Grlm549A1HZjClyjQfaLo9EgeCQcKjeC5Bj4bgCs/gBOb4f1nxl9+n4ILp72i1FERESkHHAqykVdu3bl3LlzJCYm4ufnZ2t/5JFH8PDwKLbgbiRtavgT6OPKmcR01hw8R4+GgfYOSa7FxdGmWl3Bs6JdQ6FiHRi1DBa+ANtnwoq3jOTJaoaGA6FuT/vGJyIiIlIOFGnEKTU1lfT0dFvSFBERwccff8yBAweoXLlysQZ4o3BwMNGnycXpeqquV65ZrbD7sk1vywIXDxj4P7h9Cji5QVYquPpAr3ftHZmIiIhIuVCkxGnAgAF89913AMTHx9OuXTs+/PBDBg4cyOeff16sAd5ILlbXW7r3DGmZZWy6XvwJmPMgHF1l70jKvuhdcO4gOLpC/X72jianlg8Yo0+N7oA7p4NPsL0jEhERESkXipQ4bd26lU6dOgHwyy+/EBgYSEREBN999x2ffvppsQZ4I2lZrQJVK7iTnGEm/ECMvcO5xGKBeY8aVeIWv2rvaMq+i6NNdW8DNx/7xpKboCYwZDqE9bB3JCIiIiLlRpESp5SUFLy9vQFYsmQJd9xxBw4ODtx0001EREQUa4A3EpPJRN/sIhF/lKXqepu/NqqyAZzZBecO2zeessxigd1zjePGZWSanoiIiIhcsyIlTnXq1GH+/PmcOHGCxYsXc9tttwEQExODj08Z/At7OXKxut6KfTGkZFxl09LSFHfc2EAVwNXX+Lp3nt3CKfNOboSEE0YJcBVdEBEREbluFClxGj9+PM8//zw1atSgbdu2tG/fHjBGn1q0aFGsAd5omlT1pZq/B6mZZpbvs/N0PasVfn8KMpOheke47S2jfc98u4ZVpl2sple/Lzi72zcWERERESk2RUqc7rzzTiIjI9m8eTOLFy+2tXfv3p2PPvqo2IK7EZlMJtuok92r622ZAcdWgZM73D4ZGvQHByc4sxvOHrRvbGWROQv2zjeOy0o1PREREREpFkVKnACCgoJo0aIFp0+f5uTJkwC0bduW+vXrF1twN6qL1fVWHjjLhbRM+wQRfwKWvG4cd38dAmqDhz/U6ma0XUwQ5JLjqyH5LLj7G/s3iYiIiMh1o0iJk8ViYeLEifj6+lK9enWqV69OhQoVeOutt7BYLMUd4w2nQbA3tSp5kpFlYdm+M6UfgNUKfzwNGRcgpC20e+zSe40GGV/3aJ3TFXb9anxtNBAcne0aioiIiIgUryIlTq+++ipTpkzh3XffZdu2bWzbto133nmHyZMn8/rrrxd3jDccY7qeMeq0YIcdquttnwVHlhv7EA34Hzg4Xnqvfh9wcIaYvXD2QOnHVlZlpcO+P4xjVdMTERERue4UKXH69ttv+eqrr3j88cdp2rQpTZs25YknnuDLL79kxowZxRzijal/9jqn1YfOkpBSitP1EqNg8TjjuNs4qFQ35/vuflA7e7qeikRccnAxpCeAT1Wo1t7e0YiIiIhIMStS4hQbG5vrWqb69esTGxt7zUEJhAV6Uy/Qm0yzlcV7o0vnoVYrLHgG0hKgSkto/2Tu/TRdL6f0JFg63jhucic4FHnpoIiIiIiUUUX6Da9Zs2ZMmTLlivYpU6bQtGnTAt9n0qRJtGnTBm9vbypXrszAgQM5cCD/6V9z5syhfv36uLm50aRJExYuXFio+MuLS9X1Smm63q45cPAvYyregP+Bo1Pu/eplT9c7uw9i9pVObIWRFAM758D5I6XzvKWvQ9wx8AmBTs+VzjNFREREpFQVKXH6v//7P7755hsaNmzIyJEjGTlyJA0bNmTGjBl88MEHBb7PqlWrGD16NP/88w9Lly4lMzOT2267jeTk5Ktes27dOoYOHcrIkSPZtm0bAwcOZODAgezevbsoH6VM69fMWOe09vA5YpMzSvZhF87AXy8ax11egsCGV+/rXgHqdDeOy8p0vfhIWP8ZfNMbPqgLc0fBNz2NqYcl6fAy2PyNcTzwf+DmW7LPExERERG7MFmtVmtRLjx9+jT/+9//2L9/PwANGjTgkUce4e233+aLL74oUjBnz56lcuXKrFq1is6dO+fa5+677yY5OZkFCxbY2m666SaaN2/O1KlT831GYmIivr6+JCQk4OPjU6Q4S1PfT9ew53Qi7wxqwr3tqpXMQ6xW+PkBo7hBUFN4eEX+VeF2/ATzHoVK9WH0hpKJKz/nDsG+3424T2/L+Z6Lt1EVsFp7GP5HyVS5S42Dz9rDhSho+wj0eb/4nyEiIiIiJaYwucFV5mLlr0qVKvznP//J0bZjxw6+/vrrIidOCQkJAPj7+1+1z/r163n22WdztPXs2ZP58+fn2j89PZ309HTbeWJiYpFis5e+TYPZczqRBTtPl1zitGeekXw4OMHAzwqWZNTrDY4ucHa/MV2vcoOSie1yVitE7zJi3fe78eyLTA5QrYOxSW/9vmDOgC+6QuR6WPYm9PzP1e5adAtfNJIm/9rQY0Lx319EREREyowiJ07FzWKxMHbsWDp27Ejjxo2v2i86OprAwMAcbYGBgURH515AYdKkSUyYUH5/qe3XpAr/t+gA/xw9z9kL6VTydi3eBySfg4XPG8ednoOgJgW7zs0Xanc31kTtmVdyiZPFAic3XRpZio+49J6DM9TqYiRL9fqCV6Wc1w78DGbfD+unQGhbaDig+OLa+xvs+tlI2AZNAxeP4ru3iIiIiJQ5Zab81+jRo9m9ezc//fRTsd533LhxJCQk2F4nTpwo1vuXtGoBHjQL8cVihb92l8B6nYUvQMp5qNwIOj1fuGsvr65XtBmfeTu8HD5qCN/cZiQ/8RHg5G4kSnd8CS8chvt/hVYjrkyawOjXIbsy4PzRcO5w8cSVFAN/jDWOO46F0DbFc18RERERKbPKxIjTmDFjWLBgAatXryYkJCTPvkFBQZw5cyZH25kzZwgKCsq1v6urK66uxTxKU8r6Na3CjpMJLNgRxbD2NYrvxvv+gD1zweRoFDZwcinc9fV6G5vknjtobIgb2Kj4YstIgflPQFI0uPpA3V5GIlSnO7h4Fvw+3d+Ek1sgcp2xjmvUssJd/29WK/zxNKTGQmBj6Ppy0e8lIiIiIuVGoRKnO+64I8/34+PjC/Vwq9XKk08+ybx58wgPD6dmzZr5XtO+fXuWL1/O2LFjbW1Lly6lffvrd9PRvk2D+c/CfWyKiCU6IY0gX7drv2lKLCzIXivW8Wmo0qLw93DzgTo94MCfRnW94kycNkw1kqYK1WD0RnB2L9p9HJ1gyHSY2slI7hY8C4OmgslUtPttnwUHFhrTBAdNA6fynZSLiIiISMEUaqqer69vnq/q1aszbNiwAt9v9OjRzJw5k1mzZuHt7U10dDTR0dGkpqba+gwbNoxx48bZzp9++mkWLVrEhx9+yP79+3nzzTfZvHkzY8aMKcxHKVeqVHCnVXU/rFb4c1cxTddb9DIkx0DFekb58aJqNND4WpzT9VLjYO3HxnG3V4ueNF3kHQR3fmOsR9r5E2yZXrT7xEfCX9nfq26vQNDV1+KJiIiIyPWlUCNO06cX8RfOq/j8888B6Nq16xXPGTFiBACRkZE4OFzK7zp06MCsWbN47bXXeOWVVwgLC2P+/Pl5FpS4HvRrGsyWiDgW7DzNyJvzH5nL04FFsHO2kUgM+B84X8MIVt1exnS984fgzJ7iSSb+/gjSEox1V02GXPv9AGp2gu5vwLI3jOQnuDlUbVnw6y0WY+pgxgUIaWuM0omIiIjIDcOua5wKsoVUeHj4FW1DhgxhyJBi+oW6nOjTJJiJC/ayLTKek3EphPgVsYpbajwsGGsc3/TEtRc2cPOBsFth/wJj1OlaE6fE07BhmnHcfTw4OF7b/S7X8Wk4sdGYWvjzcHh0FXhcvfR9Dhu/gONrwNnDmOpXnHGJiIiISJlXZqrqSd4CfdxoW8P4Jf/PndcwXW/ZG5f2HrrlteIJrjir64W/C1lpxsa1dXtee2yXM5mMEuV+NSEhEuY+Yowk5efcIeP7BnDrRAioXbxxiYiIiEiZp8SpHOnXrAoAC4qaOJ0/Alu/M45vn3zta4cuqtvTmK4XewTO7C76fc4dgm0zjeMebxa9gENe3CvAXd+BkxscXgprPsy7vzkL5j1qJHO1ukLrkcUfk4iIiIiUeUqcypHejYNwMMGuUwkcP5dc+Buseg+sFgjrCTU6Fl9grt7GdD0wRp2KasVbYDVD3d5Q7abiiS03wU2hb3bCtPI/cGTF1fuu/QhObQFXX2M9mIP+lRERERG5Eem3wHKkopcrHWpXBIpQXe/sAdg1xzjuNi7vvkVxrdP1Tm2Bvb8BJuj+erGGlqsW90OLBwAr/DoKEk5e2SdqJ4S/Zxz3fg98895jTERERESuX0qcypl+TYMB+GPH6cJdeHG0qV7fou3ZlJ+6vYzpb7FHIXpn4a9fNsH42uye4t0PKi993oegJpByHuaMgKyMS+9lpRtT9CyZUL+fEZeIiIiI3LCUOJUzvRoH4eRgYn/0BQ7HJBXsoph9sHuucdz15ZIJzNULwm4zjvfML9y1R1bCsVXg6AJdS2A07Gqc3eGu741peCc3wdLLRrpWvmNsmOtREfp/UjLrrURERESk3FDiVM5U8HDh5rDs6XoFLRIR/i5ghQa3G+t7SkpRNsO1WGDZm8Zx65HgV70kIrs6/5pGeXGADVNh968Q+Q+s/cRo6/8JeFYs3ZhEREREpMxR4lQO9WtqVNebs+UEiWmZeXeO3g175wOmkh/NCesJTu4QdwyidhTsmr3zIWo7uHhBp+dKMrqrq98Hbn7GOP7tSfj1YcAKzYZCg372iUlEREREyhQlTuVQz0aBVPZ25WRcKk/M3EpGVh57EYVPMr42GgSBDUs2MFcvqHtxul4BquuZM2HF28ZxhyfBq1LJxZafbq9BjU6QmWzs8eRTFXq9a794RERERKRMUeJUDnm7OfPNiDZ4uDjy9+FzjJu7C2tuU+NOb4f9CzBGm0pobdO/Faa63rbvjb2fPCpC+9ElH1teHJ3gzm/AOxgwGaXH3SvYNyYRERERKTOUOJVTjav68r97W+LoYOLXrSf5ZPmhKzuFZ4+YNBkClepd0/MW7oqi5VtLGfTZWj4PP8KRs1cpTBF2Gzh7QHyEMQXvajJSLpX67vyCsReUvXlVhkdWweProHY3e0cjIiIiImWIEqdyrFv9yrw1oDEAHy87xJzNJy69eWoLHPwLTA7Q5aVres5PGyMZM2srsckZbIuM571F++n+4Sq6fxjOe4v2szUyDosle3TJxfOy6np5TNfbMBWSoqFCNWj94DXFV6y8A0t+SqOIiIiIlDtKnMq5e9tV4/GutQEYN3cXfx86Z7yxMnttU9O7oWKdIt9/6qojvDx3FxYr3NMmlLcHNqZz3Uo4O5o4cjaZz8OPcMdn62g3aTmvzNvFygMxZDYYYFx8tel6qXGw9mPjuNur4ORa5PhEREREREqDyZrr4pjrV2JiIr6+viQkJODj42PvcIqFxWLl6dnb+WPHabxdnfhjkAs15g8EkyOM2QQBtQt9T6vVynuLDjB11REAHu9amxd71sOUvZ9RYlomqw6cZcneM6zcH0NSepbt2oquZtY6PIyrNY2kYUvwqtUu582XjjfKfVduBI+tAQfHIn/2y+M9cjaJzcfj2BwRx44T8bg4OVA9wINq/p5U8/fIPvYg2NcNJ0f9zUBERETkRleY3MCplGKSEuTgYOKDIU05k5jGxmOxnPntP9QAaD60SEmT2WLltfm7+XFjJAAv967PY11y3sfHzZn+zarQv1kV0rPM/HM0lqV7o1m69wxnEtNZ4tyc/o7/8OP0T1ld4yk61K5IjQAParklUnfDNEwA3ccXOWlKyzSz+1QCm47HsSUili0RccSlXFmafc/pxCvanBxMhPi5Uy3Ak2r+7lT396RadlJVzd8DT1f9ayEiIiIiOWnE6ToSn5LB+Mlf8WnqOLJwJP3xTXgGFi5xysiy8MzP2/lzZxQmE7wzqAlD21Yr8PUWi5WdpxI4tuZHBh18mZPWityc/gkYqRLvOH3JvU4r2UZ9JlT8kOoVPanu70G1AE+qB3hQ3d+DSt6utpGti2KTM9gSEcfmiFg2H49j18kEMsw5y7C7OTvQLKQCbWr407J6BSwWiIhNIfJ8MpGxKUTEpnAyNvWK6/4twNOFKhXcCfZ1s30NruBO1QpuBPu6U9nbVSNWIiIiIteBwuQGSpyuM2lf9cXt5N/MyrqFRbXG8fXw1jgX8Jf8lIwsHp+5lVUHz+LsaOLju1vQt2lw0QLJTIX/qw2Zycxr/R3hSdXIPHOQT+MewwkLg9PfYIs190p/7s6OxuhPgAfebk7sOBHPkbPJV/Sr6OVK6+p+tK7hR+sa/jQM9sHFKe/ParZYOZOYRsT5FE7EphARm3zZcQrxuYxa/ZuDCQJ93C5LqC4lWbUreVEjwEOJlYiIiEg5oMQpD9d14nRsDXzbD4uDMz0yP+Zoph/3tAll0h1NrhjB+beElEwe+nYTWyLicHd2ZOoDrehS9xo3pP3lIdj9K7QfAz3/Az8Pg72/kVWnJwdu+ZLI80ayEnE+hcjsBOZ0fCqWq/xE1qnsRZsafrSq7k/r6n5UD/DI93MVVkJqJifjUoiKTyMqIZXTCWlExadyOj6N0wmpnElMI9Oc978yLo4O1KrkSd1Ab+oFeRNW2Yu6gd6E+nvg6FC88YqIiIhI0WmN043IaoVwo5KeQ6vhjKt5K49+v5mfNp0g1N+D0d2uXlkv5kIaw77eyP7oC/i4OTH9wTa0qu5/7TE1GmQkTnvmQ6M7YO9vgAmnW9+gUaAvjar4XnFJRpaFU/GpRGRPr4tLzqRxVR9aVvPDz9Pl2mPKh6+7M77uuccGxlTEc0npnE5I43R8KqfjU4lKMJKsk3GpHI5JIiXDzP7oC+yPvgA7Ll3r5uxAnewkqm6gN/UCvQkL9KJqBfdiTwBFREREpHhpxOl6cTQcvhsAjq7w1Dbwrcp3648z/rc9AHx8d3MGtqh6xWUnYlN44OsNHD+fQkUvV74f2ZYGwcX0fclMhffrQEYSVKhubIrbbCgMmlo89y+DLBYrp+JTOXjmAgfOXODQmSQORF/g8NkkMrJyX1vl6eJIcAV3vFydLr3cch57ujrhnX3u6eqEd/b7FTycqeBR8gmliIiIyPVII043GqsVVr5jHLd+EHyNBGlY+xqciE3hyzXHeOGXHQT6uNG+doDtskNnLnD/1xs4k5hOiJ87M0e2o0ZFz+KLy9kd6vaC3b8YSZOjC3QdV3z3L4McHEyE+nsQ6u9B9waBtnazxUrE+WQOnkni4JkLttfRs8kkZ5g5HJNU5Gf6e7pQu5IntSt5UaeyF7UrGa+qfu6aGigiIiJSTDTidD04vAxmDgYnN3h6B3gH2d6yWKyM+XErC3dF4+PmxK+PdyAs0JvtJ+IZMX0j8SmZhFX24vuR7QjydSv+2PYtgNn3GcftHofe7xb/M8qxTLOF4+eSOZeUQVJ6FknpmSSlZZGUbr7yOD37OM04Tk4359g/699cnRyoWdGT2pW9qFPJi9qVvWwJlpvzte+dJSIiIlLeacTpRnL5aFObUTmSJjBGQP57V3POJG5gS0QcI6Zv4sVe9Xhl7i6SM8w0C63AjBFtSm79UJ0e4FMVstKh03Ml84xyzNnRgbBAb8IC8++bm5SMLI6eTebI2SSOxCRx5Gwyh2OSOHYumfQsy6W1VpcxmaBqBXdurlORvk2DaV8rQFUARURERPKhEafy7uBimHUXOHsYo01elXPtFpucweDP13Hs3KWy3h3rBPDFA61LfsPX1DgjwfMohoITUiBmi5WTcSkcjkniyNmk7K9GUpWQmrPkur+nCz0bBdGvaTDtavoriRIREZEbRrkpR7569Wref/99tmzZQlRUFPPmzWPgwIFX7R8eHk63bt2uaI+KiiIoKCiXK650XSVOVit80QWidkDHp+HWiXl2jzifzKDP1hGbnEHPRoF8OrQFrk6asnUjsVqtnE/OYO/pRBbtiWbR7mhikzNs71f0cqFX4yD6NqlC25r+WiMlIiIi17VyM1UvOTmZZs2a8dBDD3HHHXcU+LoDBw7k+GCVK+c+ynLdO7DQSJpcvKDD0/l2rx7gyW+jO7L9RDy9GwdpZOEGZDKZqOjlSue6lehctxITb2/EP0djWbDzNIv2RHMuKYOZ/0Qy859IKnm70qdxEH2bVqF1dT8cSjCJslisXEjPIjE1k4TUTBLTMklMzSQxNYvEtEzCAr3pWFtTCkVERMR+7Jo49e7dm969exf6usqVK1OhQoUC9U1PTyc9Pd12npiYWOjnlUkWC6w09m2i7SPgGZB3/2wXK76JADg5OnBzWEVuDqvIWwMbs+7Ief7ceZrFe85w9kI6366P4Nv1EQT6uNK7cTD9mgbTPLQCGWYLqRlmUjPNpGWaSc2wkJZl/ldb9tdMC6mZZlIzskhMzbIlRravKZlcSM8iv7Hvil4u9GtahUEtqtI0xFd7X4mIiEipKpfFIZo3b056ejqNGzfmzTffpGPHjlftO2nSJCZMmFCK0RVCYhSkxhplu53cja/O7kbZ7vx+Kdy/AM7sAhdv6PBk6cQr1zVnRwe61K1El7qVeHughbVHzrFgRxRL9kZzJjGdGeuOM2Pd8RKNwdXJAV93Z3zcnY2vbk64uzjyz9FYziVl2GKoVdGTAc2rMrBFFaoHFGMJfREREZGrKDPFIUwmU75rnA4cOEB4eDitW7cmPT2dr776iu+//54NGzbQsmXLXK/JbcQpNDS0bKxxWjYB/v5vLm+YjGIPzm6XJVRuOZOrqJ1w4TR0fhFuebXUQ5cbR3qWmb8PnePPnVEs2XsmRwl0VycH3F0ccXNyNL46O+LufKnNzcURd+fsl4sjPm5OtsTIx90ZH7fsBMndCR8356uWSc80W1hz6Czztp1m6d5o0jIvbSbcsloFBraoSt8mwQR4uZb490NERESuH+WmOMTlCpI45aZLly5Uq1aN77//vkD9y1RxiPB3YeOXkJUGmSlgteR/zeXcfI1Keu5+JROfyL9kZFm4kJZpS4xKct3T1SSlZ7F4dzTzt59i7eFzWLL/C+bkYKJL3UoMaFGVWxsE4u6iwiciIiKSt3JTHKI4tG3blr///tveYRRN15eNFxgV8syZkJUKmdmviwlVZtpl7ReP06DaTUqapFS5ODnYfVTHy9WJwa1CGNwqhJjENH7fcZrftp9m16kElu+PYfn+GDxdHOnZOIg7W4XQvlaA1kOJiIjINSv3idP27dsJDg62dxjXzmQCJxfj5eZr72hEyoXKPm6M6lSLUZ1qcTjmAvO3nWb+9lOcjEtl7tZTzN16ig61A3ilTwMaV9W/VyIiIlJ0dk2ckpKSOHz4sO382LFjbN++HX9/f6pVq8a4ceM4deoU3333HQAff/wxNWvWpFGjRqSlpfHVV1+xYsUKlixZYq+PICJlRJ3K3jzfsx7P3VaXLRFx/Lr1FL9uOcm6I+fpP+VvBjWvyvM961Glgru9QxUREZFyyK6J0+bNm3NsaPvss88CMHz4cGbMmEFUVBSRkZG29zMyMnjuuec4deoUHh4eNG3alGXLluW6Ka6I3JhMJhOta/jTuoY/T3StzQdLDvDb9tPM3XaKP3dF8dDNNXm8a2183JztHSpgFL4IP3CWY+eSuK9ddTxdy/1EABERketSmSkOUVrKVHEIESkVO0/G858/97HhWCwA/p4uPN09jHvbVcPZTpvq7j2dyC9bTvLb9lOcT84AoFmIL9+MaGP3dWQiIiI3inJZVa+0KHESuTFZrVaW74th0l/7OHI2GYCaFT15qVd9ejYKLJUCEueT0vlt+2l+2XKSvVGXNuOu6OVKptlCQmomNSt68t1DbbVRtYiISClQ4pQHJU4iN7Yss4WfNp3g42UHOZdkjPS0qeHHK30a0KJa8VepzMiysPJADL9sOcnK/TFkZddPd3F0oEfDygxuGULnupWIjE1h2NcbORWfSmVvV759qC0NgvXfKBERkZKkxCkPSpxEBIz9oKatOsKXa47aNtTt2zSYl3rWp1rAtY/27DmdkD0V7zSx2VPxAJqG+HJnqxD6N62Cn6dLjmuiE9IY/s1GDpy5gLerE18Ob81NtQKuORYRERHJnRKnPChxEpHLRSek8eGSA/yy9SRWKzg7mrj/puo0DfHF0cEBJwcTDiYTTg4mHB2zvzqYcDSZcHI02fo4Zm8GvPbwOX7ZcpL90Rdsz6jk7codLaoyuFUIdQO984wnITWTh7/dzMbjsbg4OfDpPc3p1fg62HJBRESkDFLilAclTiKSm72nE5n01z7WHDpXLPdzcXTg1oaB3NkqhE5hFXEqRBGKtEwzT/24jSV7z2AywVsDGnP/TdWLJS4RERG5RIlTHpQ4iUheVh88y48bI0lKz8JssZJlsdq+WmznFlu7+bL3zRYr1QM8uKNlCP2bBlPBwyX/B16F2WLltfm7+XGjsSXD093DGNsjrFSKWIiIiNwolDjlQYmTiJQXVquVj5cd4pPlhwAY2rYabw9sbJsWKCIiItemMLmBfTYwERGRfJlMJp65tS5vD2yMyQQ/bozk8ZlbSMs02zs0ERGRG44SJxGRMu7+m6rz2b0tcXF0YMneMwz7eiMJqZn2DktEROSGosRJRKQc6N0kmO9GtsXb1YmNx2O5a+p6ohPS7B2WiIjIDUOJk4hIOXFTrQBmP9qeSt6uHDhzgcGfr+NwTJK9wxIREbkhqDiEiEg5cyI2hWHfbOTYuWT8PJwZ1akWlbxcqejtQkUvV9vLxUl/GxMREcmLqurlQYmTiFwPziel89CMTew4mXDVPr7uzlT0yk6mvF2N5MrrUnJVL8ibUH+PUoxaRESkbFHilAclTiJyvUhOz2LGuuMcPZvMuaR02+t8UgZZlvz/024ywcDmVRnbI4zqAZ6lELGIiEjZosQpD0qcROR6Z7FYSUjN5FxSOmeT0jmXlMG5C5cSq7MX0jmTmM7eqEQAnBxM3N0mlCdvCSPI183O0YuIiJQeJU55UOIkImLYeTKeD5YcZPXBswC4OjkwrH11Hu9aB39PFztHJyIiUvKUOOVBiZOISE7/HD3PB4sPsDkiDgBPF0dGdqrFqE418XFztnN0IiIiJUeJUx6UOImIXMlqtRJ+8CwfLD7AntPGFL4KHs483qU2w9rXwN3FsUj3zciycPDMBXadSmDP6QSsVgjwdCHAy5UALxf8PY1iFf6eLvh5uODoYCrOjyUiIpInJU55UOIkInJ1FouVRXui+XDJAY6cTQagsrcrT95Sh7vbVMuzxHmm2cKhM0nsOhXPzpMJ7D6VwL6oC2SYLQV6tskEfh4uBHheSqguJlc1Ajzp1TgIN+eiJXAiIiK5UeKUByVOIiL5yzJbmLftFB8vO8Sp+FQAQvzcGdujLoNaVMVqtXLkbDI7T8az61QCO08msC8qkfSsK5MkX3dnmlT1pXFVX1ydHIhNzuB8slG0IjY5g/NJ6cSnZpLf/40qe7vycKda3NuuGp6uTiXxsUVE5AajxCkPSpxERAouPcvM7E0nmLziMGcvpAMQ6ONKQmomaZlXJknerk40CfGlSVVfmoT40rRqBUL93TGZ8p6Cl2W2EJeSyfnkdGKTMjiXnEFsUjrnkzM4l5RB+IEYohLSAPDzcObBjjUZ3qEGvu5agyUiIkWnxCkPSpxERAovNcPMt+uP83n4ERJSMwGjiETjqpclSSEVqO7vgUMJrFPKyLIwb9tJPg8/wvHzKQB4uTrxQPvqjLy5JhW9XIv9mSIicv1T4pQHJU4iIkWXmJbJlog4Qv08qFXRs0SSpLyYLVb+3BXFZysPsz/6AmCUUR/athqPdK5FlQrupRqPiIiUb4XJDa6+yrcUrF69mv79+1OlShVMJhPz58/P95rw8HBatmyJq6srderUYcaMGSUep4iIGHzcnOlWrzJ1KnuVetIE4Ohg4vZmVVj4VCe+HNaaZqEVSM+yMGPdcbq8v5KXftnJ8XPJ1/wcs+WG+puiiIgUgF1X1yYnJ9OsWTMeeugh7rjjjnz7Hzt2jL59+/LYY4/xww8/sHz5ckaNGkVwcDA9e/YshYhFRKQscHAwcWvDQHo0qMzaw+eZsvIQ/xyNZfbmE8zZcoJ+Taswulsd6gV5X3HthbRMziSmEZ2QTnRiWvZxmu34TGIaZy+kUzfQm0/uaZHrPURE5MZTZqbqmUwm5s2bx8CBA6/a56WXXuLPP/9k9+7dtrZ77rmH+Ph4Fi1aVKDnaKqeiMj1aUtELFNWHGblgbO2tlvqV8bX3dlIjhLTOJOQRnKGucD3dHd2ZNIdTRjYompJhCwiInZWmNygXNVzXb9+PT169MjR1rNnT8aOHXvVa9LT00lPT7edJyYmllR4IiJiR62q+zP9wbbsOZ3AZyuPsHB3FCv2x+Ta19vNiSAfN4J83ajs7UaQrytBPm4EZrd5uTrxxu97WHPoHGNnb2drZByv9W2Y5z5WIiJyfStXiVN0dDSBgYE52gIDA0lMTCQ1NRV39ysXBU+aNIkJEyaUVogiImJnjar48r/7WnI4Jok/dpzG3cWRQB9XIynKTow8XPL/39+MB9vyybKDfLriMN+tj2DnyQQ+u6+lClCIiNygrvs/nY0bN46EhATb68SJE/YOSURESkGdyl48c2tdHutSm0EtQuhQuyK1KnkVKGkCoxDFs7fV45sRrfFxc2L7iXj6Tf6btYfPlXDkIiJSFpWrxCkoKIgzZ87kaDtz5gw+Pj65jjYBuLq64uPjk+MlIiJSULfUD+TPpzrRqIoPsckZPPD1Bv638jAWVd4TEbmhlKvEqX379ixfvjxH29KlS2nfvr2dIhIRkRtBqL8Hvz7egbtah2CxwvuLD/DI95tJSMkstmdcSMtUGXQRkTLMrmuckpKSOHz4sO382LFjbN++HX9/f6pVq8a4ceM4deoU3333HQCPPfYYU6ZM4cUXX+Shhx5ixYoV/Pzzz/z555/2+ggiInKDcHN25P/ubEar6n68/tselu2Lof+Uv/n8/pY0quJb6PuZLVZ2nIxn5f4YVuyPYc/pRHzdnbm5TkW61K1E57qVCPJ1K4FPIiIiRWHXcuTh4eF069btivbhw4czY8YMRowYwfHjxwkPD89xzTPPPMPevXsJCQnh9ddfZ8SIEQV+psqRi4jItdp9KoHHZm7hZFwqrk4OvD2wMUNah+Z7XUJqJmsOnWXF/hjCD5wlNjkjz/51A71sSVSbGv64OTsW10cQEREKlxuUmX2cSosSJxERKQ7xKRk8M3u7bd+ooW1DeaN/oxzJjdVq5cjZJFbsj2H5vhg2R8TlmI7n7epE57qVuKV+ZTqFVeREXCqrD55l1cGz7DgZz+X/h3ZzduCmWgG2RKpWRU9MJlOpfV4RkeuREqc8KHESEZHiYrFYmbLyMB8tO4jVCk2q+vLxPc05GZfKin1nWHEghhOxqTmuqVPZi1vqV6Zbvcq0ruGHs2Puy43jkjP4+/A5WyIVcyE9x/tVK7jTpV4lOodVokOdAHzcnEvsc4qIXK+UOOVBiZOIiBS31QfP8vRP24jLpViEi6MDN9UO4JZ6lbilfiDVAjwKfX+r1cqBMxdsSdSmY3FkmC229x1Mxv5V7Wr6065WAG1r+OProURKRCQ/SpzyoMRJRERKwsm4FEb/sJUdJxMI9HG1jSp1rFMRT9fircWUkpHFP0fPs/rgOVYdPMuxc8k53jeZoH6QD+1q+nNTLX/a1PAnwMu1WGMQEbkeKHHKgxInEREpKVlmC6fj0wj1dy/V9UdRCalsPBbLP0dj2XDsPEfPJl/RJ6yyF+1q+dOuZgDtavlT2VsV+0RElDjlQYmTiIhc72IupLHxWCwbshOpg2eSruhTq6In7WoF0K9pMO1rBeDgoEITInLjUeKUByVOIiJyo4lNzjASqWPn2XA0ln3RiTkq9lWt4M7gViEMaRVCqH/h12CJiJRXSpzyoMRJRERudAkpmWw6HsuKAzH8seM0F9KybO+1rxXAkNYh9G4cjLuL9o0SkeubEqc8KHESERG5JC3TzOI90fyy5SR/Hz5nG4nycnWiX9NghrQOoWU1P+0ZJSLXJSVOeVDiJCIikrtT8an8uuUkv2w5SWRsiq29ViVP7mwVwuCWIQT6qKiEiFw/lDjlQYmTiIhI3iwWKxuPxzJn80kW7ooiNdMMGPtFda5biSGtQunRsDKuTprKJyLlmxKnPChxEhERKbik9Cz+3HmaOZtPsjkiztZe2duVUZ1qcm+76ngV8z5VIiKlRYlTHpQ4iYiIFM3Rs0n8suUkv249yZnEdAB83Z0Z3qEGD3aogZ+ni50jFBEpHCVOeVDiJCIicm0ysizM336KqeFHOHrO2GzX3dmRoW2r8XDnmgT7uhfLcxJSMlm67wx/7Ypi7ZFzeLs5E+rnTjV/D6r5exCa/arm70GgjxuO2otKRApJiVMelDiJiIgUD7PFyuI90fxv5WH2nE4EwNnRxB0tQnisa21qVvQs9D1jkzNYsieahbujWXf4HFmWgv2a4uLoQIifOyH+HlTzv5Rchfh5EOrngY+7kyoDisgVlDjlQYmTiIhI8bJaraw+dI7PVh5mw7FYwCgk0btJME90rU2jKr55Xh9zIY3Fe4yRpQ3HYjFflizVD/Kmd+NgejSsjMUCkbEpRMamcCIuhRPZx6fiUvNNsNydHQn2dSMo+2UcuxPsc+nc39NFyZXIDUaJUx6UOImIiJScLRGxfLbyCMv3x9jautarxBNd69C2pr+tLTohjUW7o1i4O5pNx2O5/LeRRlV86NMkmF6Ng6hdySvfZ2aZLUQlpOVIpiJjU23HsckZBYrdxcmBoMsSqRoBnozQ2i2R65oSpzwocRIRESl5+6MT+Tz8CH/sOM3FwaDW1f3oUrcSKw/EsDUyPkf/ZqEV6NM4iN6Ng6kW4FGssaRlmolOSCMqIY3oxFTj68Xz7K/nktJzvTbY141Ph7agTQ3/XN8XkfJNiVMelDiJiIiUnojzyUxbfZRfNp8kw2zJ8V7r6n70ahxEr8ZBhPgVb7JUWBlZFmIuXEqkohJS+WnTCY6eTcbRwcSzt9bl8S61cVABCpHrihKnPChxEhERKX1nEtP4Zu0xjsQk0ymsIj0bBRHk62bvsPKUnJ7F6/N3M3fbKQA6hVXkv3c1p5K3q50jE5HiosQpD0qcREREpDB+2XKS1+fvJjXTTEUvVz65pzkd61S0d1giUgwKkxs4lFJMIiIiIuXSna1C+OPJjtQL9OZcUjr3f72BD5ccIOtfUw9F5PqmxElEREQkH3Uqe/PbmI4MbVsNqxUmrzjMvV9uICoh1d6hiUgpUeIkIiIiUgBuzo5MuqMJnw5tgZerExuPx9LnkzWs2H/G3qGJSCkoE4nT//73P2rUqIGbmxvt2rVj48aNV+07Y8YMTCZTjpebW9leXCoiIiLXj9ubVWHBkzfTpKovcSmZPDRjM+8s3EdGlqbuiVzP7J44zZ49m2effZY33niDrVu30qxZM3r27ElMTMxVr/Hx8SEqKsr2ioiIKMWIRURE5EZXo6Invzzengc71gDgi9VHGTJtPSdiU+wbmIiUGLsnTv/97395+OGHefDBB2nYsCFTp07Fw8ODb7755qrXmEwmgoKCbK/AwMBSjFhEREQEXJ0ceaN/I6Y90AofNyd2nIinz6dr+GtXlL1DE5ESYNfEKSMjgy1bttCjRw9bm4ODAz169GD9+vVXvS4pKYnq1asTGhrKgAED2LNnz1X7pqenk5iYmOMlIiIiUlx6Ngpi4dOdaFmtAhfSsnj8h608+v1mwg/EYLbcULu+iFzX7Jo4nTt3DrPZfMWIUWBgINHR0bleU69ePb755ht+++03Zs6cicVioUOHDpw8eTLX/pMmTcLX19f2Cg0NLfbPISIiIje2ED8PZj/anse61AZg8Z4zjJi+iU7vreC/Sw6UqSl8VquV6IQ0Vuw/w+fhR1iw8zSZKq0uki+7boB7+vRpqlatyrp162jfvr2t/cUXX2TVqlVs2LAh33tkZmbSoEEDhg4dyltvvXXF++np6aSnp9vOExMTCQ0N1Qa4IiIiUiL2RSUye9MJ5m07RUJqJgAmE3SsXZG72oRyW8NA3JwdSyWWTLOFI2eT2Hs6kb2nE9kXbXyNS8nM0a+KrxsP3VyTu9uE4u3mXCqxiZQFhdkA16mUYspVxYoVcXR05MyZnGU8z5w5Q1BQUIHu4ezsTIsWLTh8+HCu77u6uuLq6nrNsYqIiIgURINgH968vREv967P4j3R/Lz5BGsPn+fvw+f4+/A5fN2dGdSiKne1DqVhleL7I25CSiZ7oxLZF5Vo+3roTBIZuYwmOTqYqF3Jk7DK3mw4FsvphDTe/nMfnyw7xL3tqjGiYw2Cfd2LLTaR64FdR5wA2rVrR9u2bZk8eTIAFouFatWqMWbMGF5++eV8rzebzTRq1Ig+ffrw3//+N9/+hckqRURERIrDidgU5mw+wZwtJ4lKSLO1N6nqy11tQrm9WRV83a8+0pNptnD2QjpRCWmcSUzL+TUhjZNxKZy+7L6X83Z1okGwDw2r+NAg2JuGwb6EBXrZRr3SMs38tv0UX6w+ypGzyQA4OZi4vVkVRnWqVazJnUhZU5jcwO6J0+zZsxk+fDjTpk2jbdu2fPzxx/z888/s37+fwMBAhg0bRtWqVZk0aRIAEydO5KabbqJOnTrEx8fz/vvvM3/+fLZs2ULDhg3zfZ4SJxEREbEXs8XKmkNn+XnzCZbuPUOm2fg1zNXJgT5NgmlfK4CzSek5kqPohDTOJqVTkN/YQvzcjSQp2IcGwT40quJDiJ87JpMp32stFivhB2P4YvVR/jkaa2vvFFaRhzvVolNYxQLdR6Q8KTdT9QDuvvtuzp49y/jx44mOjqZ58+YsWrTIVjAiMjISB4dLNSzi4uJ4+OGHiY6Oxs/Pj1atWrFu3boCJU0iIiIi9uToYKJrvcp0rVeZ80npzNt2ip83n+DgmSTmbTvFvG2nrnqtk4OJQB83gnyzXz5uBPu6EZj9NSzQO89Rq/w4OJi4pX4gt9QPZOfJeL5cc4yFu6JYc+gcaw6do36QNw93qkX/ZlVwcbL7jjYipc7uI06lTSNOIiIiUpZYrVa2n4hnzpaTRJ5PobKPqy0pCvJ1Jyg7WQrwdMHBoXRHfE7EpjB97XF+2hRJSoYZgEAfVx7sWJOhbarh4+6kUSgp18rVVL3SpsRJREREpHASUjKZtTGS6WuPEXMhPcd7Tg4mHBxMODmYcMx+2Y5NJhwdTTg5OOBgAicHB5ydTHSoXZGhbatRs6KnnT6RiEGJUx6UOImIiIgUTUaWhd93nObL1Uc5cObCNd/v5joVua9dNXo0DMTZUdP/pPQpccqDEicRERGRa2O1WklMzSLTYsFssZJlsWLJ/mq2WDBbICv7vYuvi31iUzKYu/UUKw/E2ApeVPJ25e7WodzTNpQQPw/7fji5oShxyoMSJxERERH7OxGbwuxNJ/hp0wnOJRnT/0wm6FavMve1q0bXepVxLOU1XXLjUeKUByVOIiIiImVHptnC0r1n+GFDBGsPn7e1V/F1Y2jbatzdJpTKPm52jFCuZ0qc8qDESURERKRsOno2iR83RvLLlpPEpWQCRgn3WxsEct9N1ehYu2KpVxaU65sSpzwocRIREREp29IyzSzaHc0PGyLYdDzO1l7Bw5nqAZ5U9/egeoAH1fw9jPMADyp7u6o0uhSaEqc8KHESERERKT8ORF9g1oYI5m49xYX0rKv2c3N2oJq/B9X8jUTq8sSqagV3bdoruVLilAclTiIiIiLlT1qmmSNnkzgRm0LE+RQiYlOIPJ9CRGwyp+JSseTzG62fhzMBXq4EeLpQ0cuVAC8XAjyNrxW9XGzvBXi54uOmjX1vFIXJDZxKKSYRERERkSJzc3akURVfGlXxveK9TLOFU3Gp2clUco7EKjI2hdRMM3EpmcSlZHK4AM9ydjTZkqpgXzdC/DwI8XO3fQ3198DX3bn4P6SUaUqcRERERKRcc3Z0oEZFT2pU9AQq5XjParUSm5zB+eQMziWlcz4pg/NJ6dnnl47PZ793IT2LTLOV6MQ0ohPT2HM6Mddners5EeLnQei/EiojwXLH202J1fVGiZOIiIiIXLdMJpMxDc/LlbqB3vn2T8s0G4lWkpFonYpP5WRcKifjUjgRl8qpuBTOJWVwIS2LfVGJ7IvKPbHy93ShTmUv6gZ6UTfQm7DK3tQN9CLAy7W4P6KUEq1xEhEREREphJSMLE7FGQnVibiUS4lVrPH1Yin13AR4uhB2MZkK9KZuZS/CAr3x93QpxU8gF6k4RB6UOImIiIhISUpKz+L4uWQOnrnAwTNJHPr/9u49Nqpqb+P4M9PpzLSlLb3ItAVKIdwEpb5cWiZoiLaxoCFWMSJptCAJIRYCNiQqEYvRpEaj4oVTvOIfCkhJQEUQsWKNyrVYBIMcMHjoSWlr9UDb0V7orPePyrxnXkqnFWG35ftJVrpnrTWd3yS/TPJk9t5T26h/1jWq6rc/LvmcxAFOjRoUrZGDBija7ZDLESZXuF0uh13u8DC5HPaOOYf9z/mLj+OjnHKHh13Fd9r3EZy6QHACAACAFX5vPa+TdU0dYaquUSdqm/TP2kb9+z+XDlQ9lRzr1rCESA1PjNKwhCilJUQpLTFSw+KjFOEkVP1/BKcuEJwAAADQm/haLgSqRv38q0+/t7ar5bxfLW1+tZz/8/i8Xy1t/3V8vv3P9f87bm33d/k6STFupSVG/hmmopSWEKm0xCilxkcq0nlt3vqA4NQFghMAAAD6G2OMzv7eplO/+vSvX306Vf+7/vWrTz/X+3Sq3qeG5kv/eLDUcZdAT4xbnhiXBkW7NSjGJc+FvzHuwHF/OxWQ33ECAAAAriE2m01xUU7FRTk1MTXuovX/+Fr186++jlH/+5/Hv+vnep/O/dGmxubzamxu0sm6pi5fJyYQsNwaFO2S2xmmcLtNjjC7HGE2OcPsctg7jsPDbHLY7R1/w+wKD7MH5hxhNk0ffV2fCmIEJwAAAKCfuxCq/qeTUNXQ3Ka6hhbVNTSrrrFFtQ3Nqm1oUW1jc9Bcc5tfDc3n1dDcpBMhAlZ37F+RRXACAAAA0DfEuMMV4w7XyEEDLrnHGKOG5vNBQaqusUUtbX61tfvV5vfrfLvR+Xa/2vwdf8+3m8BxW7tfbe1G5/1//m33y9WHQpNEcAIAAAAQgs1mU2xEuGIjwjWqGz8k3B/ZrS4AAAAAAHo7ghMAAAAAhEBwAgAAAIAQekVwWrNmjdLS0uR2u5WZman9+/d3ub+0tFRjx46V2+3WjTfeqO3bt1+lSgEAAABciywPTh988IEKCwtVVFSkQ4cOKT09XTk5Oaqrq+t0/7fffqu5c+dqwYIF+u6775Sbm6vc3FwdPXr0KlcOAAAA4FphM8YYKwvIzMzUlClT9Nprr0mS/H6/hg4dqiVLluixxx67aP+cOXPk8/m0bdu2wNzUqVN10003ae3atSFfrye/DgwAAACg/+pJNrD0G6fW1lZVVFQoOzs7MGe325Wdna09e/Z0+pw9e/YE7ZeknJycS+5vaWlRQ0ND0AAAAACAnrA0ONXX16u9vV0ejydo3uPxqKamptPn1NTU9Gh/cXGxYmNjA2Po0KF/T/EAAAAArhmWX+N0pT3++OM6d+5cYFRVVVldEgAAAIA+xmHliycmJiosLEy1tbVB87W1tUpKSur0OUlJST3a73K55HK5/p6CAQAAAFyTLP3Gyel0atKkSSorKwvM+f1+lZWVyev1dvocr9cbtF+Sdu3adcn9AAAAAHC5LP3GSZIKCwuVn5+vyZMnKyMjQ6tXr5bP59P8+fMlSQ8++KAGDx6s4uJiSdLSpUs1ffp0vfDCC7rzzju1ceNGHTx4UG+88Ua3Xu/CTQS5SQQAAABwbbuQCbp1o3HTC7z66qsmNTXVOJ1Ok5GRYfbu3RtYmz59usnPzw/av2nTJjN69GjjdDrN+PHjzSeffNLt16qqqjKSGAwGg8FgMBgMBsNIMlVVVSFzhOW/43S1+f1+VVdXKzo6Wjabzepy1NDQoKFDh6qqqorflUKP0Du4HPQPLgf9g8tB/+CvuhK9Y4xRY2OjUlJSZLd3fRWT5afqXW12u11DhgyxuoyLxMTE8OGBv4TeweWgf3A56B9cDvoHf9Xf3TuxsbHd2tfvb0cOAAAAAJeL4AQAAAAAIRCcLOZyuVRUVMRvTaHH6B1cDvoHl4P+weWgf/BXWd0719zNIQAAAACgp/jGCQAAAABCIDgBAAAAQAgEJwAAAAAIgeAEAAAAACEQnCy0Zs0apaWlye12KzMzU/v377e6JPRCX331lWbNmqWUlBTZbDZt3bo1aN0YoyeffFLJycmKiIhQdna2Tpw4YU2x6FWKi4s1ZcoURUdHa9CgQcrNzdXx48eD9jQ3N6ugoEAJCQkaMGCAZs+erdraWosqRm9SUlKiCRMmBH5o0uv1aseOHYF1egc98eyzz8pms2nZsmWBOXoIl7Jq1SrZbLagMXbs2MC6Vb1DcLLIBx98oMLCQhUVFenQoUNKT09XTk6O6urqrC4NvYzP51N6errWrFnT6fpzzz2nV155RWvXrtW+ffsUFRWlnJwcNTc3X+VK0duUl5eroKBAe/fu1a5du9TW1qbbb79dPp8vsOeRRx7Rxx9/rNLSUpWXl6u6ulr33HOPhVWjtxgyZIieffZZVVRU6ODBg7rtttt011136YcffpBE76D7Dhw4oNdff10TJkwImqeH0JXx48frzJkzgfH1118H1izrHQNLZGRkmIKCgsDj9vZ2k5KSYoqLiy2sCr2dJLNly5bAY7/fb5KSkszzzz8fmDt79qxxuVxmw4YNFlSI3qyurs5IMuXl5caYjl4JDw83paWlgT3Hjh0zksyePXusKhO9WFxcnHnrrbfoHXRbY2OjGTVqlNm1a5eZPn26Wbp0qTGGzx90raioyKSnp3e6ZmXv8I2TBVpbW1VRUaHs7OzAnN1uV3Z2tvbs2WNhZehrTp06pZqamqBeio2NVWZmJr2Ei5w7d06SFB8fL0mqqKhQW1tbUP+MHTtWqamp9A+CtLe3a+PGjfL5fPJ6vfQOuq2goEB33nlnUK9IfP4gtBMnTiglJUUjRoxQXl6eTp8+Lcna3nFc0f+OTtXX16u9vV0ejydo3uPx6Mcff7SoKvRFNTU1ktRpL11YAyTJ7/dr2bJlmjZtmm644QZJHf3jdDo1cODAoL30Dy44cuSIvF6vmpubNWDAAG3ZskXjxo1TZWUlvYOQNm7cqEOHDunAgQMXrfH5g65kZmbq3Xff1ZgxY3TmzBk99dRTuuWWW3T06FFLe4fgBADXgIKCAh09ejToHHEglDFjxqiyslLnzp3T5s2blZ+fr/LycqvLQh9QVVWlpUuXateuXXK73VaXgz5m5syZgeMJEyYoMzNTw4YN06ZNmxQREWFZXZyqZ4HExESFhYVddPeP2tpaJSUlWVQV+qIL/UIvoSuLFy/Wtm3btHv3bg0ZMiQwn5SUpNbWVp09ezZoP/2DC5xOp0aOHKlJkyapuLhY6enpevnll+kdhFRRUaG6ujpNnDhRDodDDodD5eXleuWVV+RwOOTxeOghdNvAgQM1evRonTx50tLPH4KTBZxOpyZNmqSysrLAnN/vV1lZmbxer4WVoa8ZPny4kpKSgnqpoaFB+/bto5cgY4wWL16sLVu26IsvvtDw4cOD1idNmqTw8PCg/jl+/LhOnz5N/6BTfr9fLS0t9A5CysrK0pEjR1RZWRkYkydPVl5eXuCYHkJ3NTU16aefflJycrKlnz+cqmeRwsJC5efna/LkycrIyNDq1avl8/k0f/58q0tDL9PU1KSTJ08GHp86dUqVlZWKj49Xamqqli1bpmeeeUajRo3S8OHDtXLlSqWkpCg3N9e6otErFBQUaP369frwww8VHR0dOPc7NjZWERERio2N1YIFC1RYWKj4+HjFxMRoyZIl8nq9mjp1qsXVw2qPP/64Zs6cqdTUVDU2Nmr9+vX68ssvtXPnTnoHIUVHRweup7wgKipKCQkJgXl6CJeyfPlyzZo1S8OGDVN1dbWKiooUFhamuXPnWvv5c0Xv2YcuvfrqqyY1NdU4nU6TkZFh9u7da3VJ6IV2795tJF008vPzjTEdtyRfuXKl8Xg8xuVymaysLHP8+HFri0av0FnfSDLr1q0L7Pnjjz/Mww8/bOLi4kxkZKS5++67zZkzZ6wrGr3GQw89ZIYNG2acTqe57rrrTFZWlvnss88C6/QOeuq/b0duDD2ES5szZ45JTk42TqfTDB482MyZM8ecPHkysG5V79iMMebKRjMAAAAA6Nu4xgkAAAAAQiA4AQAAAEAIBCcAAAAACIHgBAAAAAAhEJwAAAAAIASCEwAAAACEQHACAAAAgBAITgAAAAAQAsEJAIAesNls2rp1q9VlAACuMoITAKDPmDdvnmw220VjxowZVpcGAOjnHFYXAABAT8yYMUPr1q0LmnO5XBZVAwC4VvCNEwCgT3G5XEpKSgoacXFxkjpOoyspKdHMmTMVERGhESNGaPPmzUHPP3LkiG677TZFREQoISFBCxcuVFNTU9Ced955R+PHj5fL5VJycrIWL14ctF5fX6+7775bkZGRGjVqlD766KMr+6YBAJYjOAEA+pWVK1dq9uzZOnz4sPLy8nT//ffr2LFjkiSfz6ecnBzFxcXpwIEDKi0t1eeffx4UjEpKSlRQUKCFCxfqyJEj+uijjzRy5Mig13jqqad033336fvvv9cdd9yhvLw8/fbbb1f1fQIAri6bMcZYXQQAAN0xb948vffee3K73UHzK1as0IoVK2Sz2bRo0SKVlJQE1qZOnaqJEyfqH//4h9588009+uijqqqqUlRUlCRp+/btmjVrlqqrq+XxeDR48GDNnz9fzzzzTKc12Gw2PfHEE3r66acldYSxAQMGaMeOHVxrBQD9GNc4AQD6lFtvvTUoGElSfHx84Njr9Qateb1eVVZWSpKOHTum9PT0QGiSpGnTpsnv9+v48eOy2Wyqrq5WVlZWlzVMmDAhcBwVFaWYmBjV1dX91bcEAOgDCE4AgD4lKirqolPn/i4RERHd2hceHh702Gazye/3X4mSAAC9BNc4AQD6lb179170+Prrr5ckXX/99Tp8+LB8Pl9g/ZtvvpHdbteYMWMUHR2ttLQ0lZWVXdWaAQC9H984AQD6lJaWFtXU1ATNORwOJSYmSpJKS0s1efJk3XzzzXr//fe1f/9+vf3225KkvLw8FRUVKT8/X6tWrdIvv/yiJUuW6IEHHpDH45EkrVq1SosWLdKgQYM0c+ZMNTY26ptvvtGSJUuu7hsFAPQqBCcAQJ/y6aefKjk5OWhuzJgx+vHHHyV13PFu48aNevjhh5WcnKwNGzZo3LhxkqTIyEjt3LlTS5cu1ZQpUxQZGanZs2frxRdfDPyv/Px8NTc366WXXtLy5cuVmJioe++99+q9QQBAr8Rd9QAA/YbNZtOWLVuUm5trdSkAgH6Ga5wAAAAAIASCEwAAAACEwDVOAIB+g7PPAQBXCt84AQAAAEAIBCcAAAAACIHgBAAAAAAhEJwAAAAAIASCEwAAAACEQHACAAAAgBAITgAAAAAQAsEJAAAAAEL4X73jbHNAnSQfAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated: heureuse grâce travaille musique dur tous\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2}\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\"}\n",
    "        self.word_count = {}\n",
    "        self.n_words = 3  # Start counting from 3 to account for special tokens\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.word_count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word_count[word] += 1\n",
    "\n",
    "def tokenize_and_pad(sentences, vocab):\n",
    "    if isinstance(sentences, str):  # Handle single sentence\n",
    "        sentences = [sentences]\n",
    "\n",
    "    max_length = max(len(sentence.split(' ')) for sentence in sentences) + 2  # +2 for SOS and EOS tokens\n",
    "    tokenized_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = [vocab.word2index[\"<SOS>\"]] + [vocab.word2index[word] for word in sentence.split(' ')] + [vocab.word2index[\"<EOS>\"]]\n",
    "        padded_tokens = tokens + [vocab.word2index[\"<PAD>\"]] * (max_length - len(tokens))\n",
    "        tokenized_sentences.append(torch.tensor(padded_tokens, dtype=torch.long))\n",
    "    return tokenized_sentences\n",
    "\n",
    "class EngFrDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.eng_vocab = Vocabulary()\n",
    "        self.fr_vocab = Vocabulary()\n",
    "        self.pairs = []\n",
    "\n",
    "        for eng, fr in pairs:\n",
    "            self.eng_vocab.add_sentence(eng)\n",
    "            self.fr_vocab.add_sentence(fr)\n",
    "            self.pairs.append((eng, fr))\n",
    "\n",
    "        self.eng_sentences = [pair[0] for pair in self.pairs]\n",
    "        self.fr_sentences = [pair[1] for pair in self.pairs]\n",
    "        \n",
    "        self.eng_tokens = tokenize_and_pad(self.eng_sentences, self.eng_vocab)\n",
    "        self.fr_tokens = tokenize_and_pad(self.fr_sentences, self.fr_vocab)\n",
    "\n",
    "        self.eng_embedding = nn.Embedding(self.eng_vocab.n_words, 100)\n",
    "        self.fr_embedding = nn.Embedding(self.fr_vocab.n_words, 100)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eng_tokens = self.eng_tokens[idx]\n",
    "        fr_tokens = self.fr_tokens[idx]\n",
    "        eng_emb = self.eng_embedding(eng_tokens)\n",
    "        fr_emb = self.fr_embedding(fr_tokens)\n",
    "        return eng_tokens, fr_tokens, eng_emb, fr_emb\n",
    "\n",
    "class EncoderGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "    \n",
    "class DecoderGRU(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = torch.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "    \n",
    "dataset = EngFrDataset(english_to_french)\n",
    "train_pairs, val_pairs = train_test_split(dataset.pairs, test_size=0.2) \n",
    "\n",
    "train_dataset = EngFrDataset(train_pairs)\n",
    "val_dataset = EngFrDataset(val_pairs)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, target_vocab, max_length, teacher_forcing_ratio):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)  # Adjusted size\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[target_vocab.word2index['<SOS>']]], device=input_tensor.device)\n",
    "    decoder_hidden = encoder_hidden  # Adjusted assignment\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden\n",
    "        )\n",
    "        if use_teacher_forcing:\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "        else:\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "        if decoder_input.item() == target_vocab.word2index['<EOS>']:\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, input_vocab, output_vocab, max_length):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tokenize_and_pad([sentence], input_vocab)[0]\n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size)  # Corrected size\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[output_vocab.word2index['<SOS>']]])  # SOS token\n",
    "        decoder_hidden = encoder_hidden  # Corrected assignment\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == output_vocab.word2index['<EOS>']:\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_vocab.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return ' '.join(decoded_words)\n",
    "    \n",
    "def evaluate_loss(input_tensor, target_tensor, encoder, decoder, criterion, target_vocab, max_length):\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "        for ei in range(input_tensor.size(0)):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[target_vocab.word2index['<SOS>']]], device=input_tensor.device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        loss = 0\n",
    "        for di in range(target_tensor.size(0)):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "            if decoder_input.item() == target_vocab.word2index['<EOS>']:\n",
    "                break\n",
    "                \n",
    "\n",
    "        return loss.item() / target_tensor.size(0)\n",
    "        \n",
    " \n",
    "\n",
    "def clean_translation(translation):\n",
    "    return translation.replace('<SOS>', '').replace('<EOS>', '').strip()\n",
    "\n",
    "hidden_size = 256\n",
    "encoder = EncoderGRU(dataset.eng_vocab.n_words, hidden_size)\n",
    "decoder = DecoderGRU(hidden_size, dataset.fr_vocab.n_words)\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.01)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.01)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "\n",
    "# Training loop with validation\n",
    "for epoch in range(50):\n",
    "    total_train_loss = 0\n",
    "    for eng_tokens, fr_tokens, _, _ in train_dataloader:\n",
    "        loss = train(eng_tokens.squeeze(0), fr_tokens.squeeze(0), encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, dataset.fr_vocab, max_length=10, teacher_forcing_ratio=0.5)\n",
    "        total_train_loss += loss\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    total_val_loss = 0\n",
    "    for eng_tokens, fr_tokens, _, _ in val_dataloader:\n",
    "        loss = evaluate_loss(eng_tokens.squeeze(0), fr_tokens.squeeze(0), encoder, decoder, criterion, dataset.fr_vocab, max_length=10)\n",
    "        total_val_loss += loss\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Translate a sentence\n",
    "sentence = \"I am hungry\"\n",
    "translated_sentence = evaluate(encoder, decoder, sentence, dataset.eng_vocab, dataset.fr_vocab, max_length=10)\n",
    "print('Translated:', clean_translation(translated_sentence))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T03:41:04.058427600Z",
     "start_time": "2024-04-09T03:40:17.435174600Z"
    }
   },
   "id": "7583221986290ff2",
   "execution_count": 158
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 3.3419, Train Accuracy: 0.1514, Val Loss: 27.6879, Val Accuracy: 0.1741\n",
      "Epoch 2/50, Train Loss: 2.5450, Train Accuracy: 0.1748, Val Loss: 17.4592, Val Accuracy: 0.2181\n",
      "Epoch 3/50, Train Loss: 2.3012, Train Accuracy: 0.1936, Val Loss: 16.7099, Val Accuracy: 0.2244\n",
      "Epoch 4/50, Train Loss: 2.2940, Train Accuracy: 0.1991, Val Loss: 18.7184, Val Accuracy: 0.2529\n",
      "Epoch 5/50, Train Loss: 2.3886, Train Accuracy: 0.2031, Val Loss: 16.0489, Val Accuracy: 0.2330\n",
      "Epoch 6/50, Train Loss: 2.4231, Train Accuracy: 0.2158, Val Loss: 15.7946, Val Accuracy: 0.2244\n",
      "Epoch 7/50, Train Loss: 2.4052, Train Accuracy: 0.2247, Val Loss: 14.8404, Val Accuracy: 0.2022\n",
      "Epoch 8/50, Train Loss: 2.4663, Train Accuracy: 0.2262, Val Loss: 15.2963, Val Accuracy: 0.2445\n",
      "Epoch 9/50, Train Loss: 2.4737, Train Accuracy: 0.2155, Val Loss: 15.0975, Val Accuracy: 0.2369\n",
      "Epoch 10/50, Train Loss: 2.4323, Train Accuracy: 0.2480, Val Loss: 15.0129, Val Accuracy: 0.2290\n",
      "Epoch 11/50, Train Loss: 2.3839, Train Accuracy: 0.2412, Val Loss: 17.2206, Val Accuracy: 0.2572\n",
      "Epoch 12/50, Train Loss: 2.3401, Train Accuracy: 0.2490, Val Loss: 17.1387, Val Accuracy: 0.3313\n",
      "Epoch 13/50, Train Loss: 2.4357, Train Accuracy: 0.2795, Val Loss: 13.8133, Val Accuracy: 0.2737\n",
      "Epoch 14/50, Train Loss: 2.3549, Train Accuracy: 0.3037, Val Loss: 13.3262, Val Accuracy: 0.2767\n",
      "Epoch 15/50, Train Loss: 2.2002, Train Accuracy: 0.3247, Val Loss: 13.3215, Val Accuracy: 0.3411\n",
      "Epoch 16/50, Train Loss: 2.2263, Train Accuracy: 0.3472, Val Loss: 15.1234, Val Accuracy: 0.3671\n",
      "Epoch 17/50, Train Loss: 2.1492, Train Accuracy: 0.3559, Val Loss: 11.9290, Val Accuracy: 0.3522\n",
      "Epoch 18/50, Train Loss: 2.1517, Train Accuracy: 0.3595, Val Loss: 11.3265, Val Accuracy: 0.3572\n",
      "Epoch 19/50, Train Loss: 2.0038, Train Accuracy: 0.3905, Val Loss: 11.0822, Val Accuracy: 0.3785\n",
      "Epoch 20/50, Train Loss: 1.9786, Train Accuracy: 0.3885, Val Loss: 13.6354, Val Accuracy: 0.4243\n",
      "Epoch 21/50, Train Loss: 1.9651, Train Accuracy: 0.3945, Val Loss: 11.4726, Val Accuracy: 0.4201\n",
      "Epoch 22/50, Train Loss: 1.8192, Train Accuracy: 0.4239, Val Loss: 10.7053, Val Accuracy: 0.4067\n",
      "Epoch 23/50, Train Loss: 1.8213, Train Accuracy: 0.4153, Val Loss: 11.3474, Val Accuracy: 0.4614\n",
      "Epoch 24/50, Train Loss: 1.7608, Train Accuracy: 0.4295, Val Loss: 10.5273, Val Accuracy: 0.4568\n",
      "Epoch 25/50, Train Loss: 1.6829, Train Accuracy: 0.4460, Val Loss: 11.3473, Val Accuracy: 0.5182\n",
      "Epoch 26/50, Train Loss: 1.6399, Train Accuracy: 0.4480, Val Loss: 9.7765, Val Accuracy: 0.5179\n",
      "Epoch 27/50, Train Loss: 1.5508, Train Accuracy: 0.4711, Val Loss: 9.5831, Val Accuracy: 0.5676\n",
      "Epoch 28/50, Train Loss: 1.4599, Train Accuracy: 0.4922, Val Loss: 8.8041, Val Accuracy: 0.5908\n",
      "Epoch 29/50, Train Loss: 1.4190, Train Accuracy: 0.5247, Val Loss: 8.1374, Val Accuracy: 0.6023\n",
      "Epoch 30/50, Train Loss: 1.3180, Train Accuracy: 0.5382, Val Loss: 7.4570, Val Accuracy: 0.6531\n",
      "Epoch 31/50, Train Loss: 1.2457, Train Accuracy: 0.5921, Val Loss: 7.2030, Val Accuracy: 0.6343\n",
      "Epoch 32/50, Train Loss: 1.1667, Train Accuracy: 0.6175, Val Loss: 7.9325, Val Accuracy: 0.7736\n",
      "Epoch 33/50, Train Loss: 1.1224, Train Accuracy: 0.6289, Val Loss: 5.9278, Val Accuracy: 0.6633\n",
      "Epoch 34/50, Train Loss: 1.0435, Train Accuracy: 0.6459, Val Loss: 5.8568, Val Accuracy: 0.7759\n",
      "Epoch 35/50, Train Loss: 0.9548, Train Accuracy: 0.7132, Val Loss: 5.5023, Val Accuracy: 0.7864\n",
      "Epoch 36/50, Train Loss: 0.8923, Train Accuracy: 0.7430, Val Loss: 5.2160, Val Accuracy: 0.8146\n",
      "Epoch 37/50, Train Loss: 0.8236, Train Accuracy: 0.7392, Val Loss: 5.5353, Val Accuracy: 0.8609\n",
      "Epoch 38/50, Train Loss: 0.7800, Train Accuracy: 0.7934, Val Loss: 4.1368, Val Accuracy: 0.8709\n",
      "Epoch 39/50, Train Loss: 0.7222, Train Accuracy: 0.8075, Val Loss: 4.0911, Val Accuracy: 0.8750\n",
      "Epoch 40/50, Train Loss: 0.6671, Train Accuracy: 0.8244, Val Loss: 3.7370, Val Accuracy: 0.9033\n",
      "Epoch 41/50, Train Loss: 0.5694, Train Accuracy: 0.8472, Val Loss: 3.1576, Val Accuracy: 0.9336\n",
      "Epoch 42/50, Train Loss: 0.5029, Train Accuracy: 0.8887, Val Loss: 3.0949, Val Accuracy: 0.9450\n",
      "Epoch 43/50, Train Loss: 0.4952, Train Accuracy: 0.8619, Val Loss: 2.5072, Val Accuracy: 0.9346\n",
      "Epoch 44/50, Train Loss: 0.4319, Train Accuracy: 0.9142, Val Loss: 2.4772, Val Accuracy: 0.9331\n",
      "Epoch 45/50, Train Loss: 0.3898, Train Accuracy: 0.9132, Val Loss: 2.1893, Val Accuracy: 0.9328\n",
      "Epoch 46/50, Train Loss: 0.3601, Train Accuracy: 0.9293, Val Loss: 1.8711, Val Accuracy: 0.9593\n",
      "Epoch 47/50, Train Loss: 0.3310, Train Accuracy: 0.9464, Val Loss: 1.6849, Val Accuracy: 0.9748\n",
      "Epoch 48/50, Train Loss: 0.2867, Train Accuracy: 0.9488, Val Loss: 1.7270, Val Accuracy: 0.9661\n",
      "Epoch 49/50, Train Loss: 0.2756, Train Accuracy: 0.9570, Val Loss: 1.7204, Val Accuracy: 0.9694\n",
      "Epoch 50/50, Train Loss: 0.2854, Train Accuracy: 0.9481, Val Loss: 1.4305, Val Accuracy: 0.9768\n",
      "Translated: le bébé\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "def build_vocab(sentences):\n",
    "    tokens = [token for sentence in sentences for token in sentence]\n",
    "    vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
    "    vocab.update({token: i+3 for i, token in enumerate(set(tokens))})\n",
    "    return vocab\n",
    "\n",
    "# Custom dataset class\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_sentences, tgt_sentences, src_vocab, tgt_vocab):\n",
    "        self.src_sentences = [[src_vocab[token] for token in ['<sos>'] + sentence + ['<eos>']] for sentence in src_sentences]\n",
    "        self.tgt_sentences = [[tgt_vocab[token] for token in ['<sos>'] + sentence + ['<eos>']] for sentence in tgt_sentences]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_sentence = self.src_sentences[idx]\n",
    "        tgt_sentence = self.tgt_sentences[idx]\n",
    "        return torch.tensor(src_sentence, dtype=torch.long), torch.tensor(tgt_sentence, dtype=torch.long)\n",
    "\n",
    "# Tokenize and build vocab\n",
    "tokenized_en = [tokenize(en) for en, fr in english_to_french]\n",
    "tokenized_fr = [tokenize(fr) for en, fr in english_to_french]\n",
    "en_vocab = build_vocab(tokenized_en)\n",
    "fr_vocab = build_vocab(tokenized_fr)\n",
    "rev_fr_vocab = {v: k for k, v in fr_vocab.items()}\n",
    "\n",
    "\n",
    "train_dataset = TranslationDataset(tokenized_en, tokenized_fr, en_vocab, fr_vocab)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Encoder definition\n",
    "class EncoderGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout=0):\n",
    "        super(EncoderGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.n_layers, 1, self.hidden_size)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden: [1, batch size, hid dim], encoder_outputs: [src len, batch size, hid dim]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        hidden = hidden.repeat(src_len, 1, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        return F.softmax(attention, dim=0)\n",
    "\n",
    "class AttnDecoderGRU(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size, n_layers=1, dropout_p=0.1):\n",
    "        super(AttnDecoderGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attention = Attention(hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size + hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        attn_weights = self.attention(hidden, encoder_outputs)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs.permute(1, 0, 2))\n",
    "        gru_input = torch.cat((embedded, attn_applied.permute(1, 0, 2)), dim=2)\n",
    "        output, hidden = self.gru(gru_input, hidden)\n",
    "        output = self.out(torch.cat((output.squeeze(0), attn_applied.squeeze(1)), dim=1))\n",
    "        return F.log_softmax(output, dim=1), hidden\n",
    "\n",
    "\n",
    "# Initialize models, optimizers, and loss function\n",
    "enc = EncoderGRU(len(en_vocab), 256, 2, 0.5)\n",
    "dec = DecoderGRU(len(fr_vocab), 256, 2, 0.5)\n",
    "enc_optimizer = optim.SGD(enc.parameters(), lr=0.01)\n",
    "dec_optimizer = optim.SGD(dec.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=50):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "    correct = 0  # To calculate accuracy\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[fr_vocab['<sos>']]])\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "        if decoder_input.item() == target_tensor[di].item():\n",
    "            correct += 1\n",
    "\n",
    "        if decoder_input.item() == fr_vocab['<eos>']:\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    accuracy = correct / target_length  # Calculate accuracy\n",
    "\n",
    "    return loss.item() / target_length, accuracy\n",
    "\n",
    "# Validation function\n",
    "def validate(encoder, decoder, dataloader, criterion, max_length=50):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src, tgt = src.squeeze(0), tgt.squeeze(0)\n",
    "            loss, accuracy = evaluate(src, tgt, encoder, decoder, criterion, max_length)\n",
    "            total_loss += loss\n",
    "            total_accuracy += accuracy\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_accuracy = total_accuracy / len(dataloader)\n",
    "    return avg_loss, avg_accuracy\n",
    "\n",
    "# Evaluate function\n",
    "def evaluate(src_tensor, tgt_tensor, encoder, decoder, criterion, max_length=50):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    input_length = src_tensor.size(0)\n",
    "    target_length = tgt_tensor.size(0)\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(src_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[fr_vocab['<sos>']]])\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        if topi.item() == tgt_tensor[di].item():\n",
    "            correct += 1\n",
    "        decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        loss += criterion(decoder_output, tgt_tensor[di].unsqueeze(0))\n",
    "        if decoder_input.item() == fr_vocab['<eos>']:\n",
    "            break\n",
    "\n",
    "    accuracy = correct / target_length\n",
    "    return loss.item(), accuracy\n",
    "\n",
    "def train_loop(num_epochs, train_dataloader, val_dataloader, encoder, decoder, enc_optimizer, dec_optimizer, criterion):\n",
    "    for epoch in range(num_epochs):\n",
    "        total_train_loss = 0\n",
    "        total_train_accuracy = 0\n",
    "\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        for src, tgt in train_dataloader:\n",
    "            src, tgt = src.squeeze(0), tgt.squeeze(0)\n",
    "            loss, accuracy = train(src, tgt, encoder, decoder, enc_optimizer, dec_optimizer, criterion)\n",
    "            total_train_loss += loss\n",
    "            total_train_accuracy += accuracy\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "        avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n",
    "\n",
    "        # Validation phase with loss and accuracy\n",
    "        avg_val_loss, avg_val_accuracy = validate(encoder, decoder, val_dataloader, criterion)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_accuracy:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {avg_val_accuracy:.4f}')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "train_loop(50, train_dataloader, val_dataloader, enc, dec, enc_optimizer, dec_optimizer, criterion)\n",
    "\n",
    "# Translation function\n",
    "def translate(sentence, encoder, decoder, src_vocab, tgt_vocab, rev_tgt_vocab, max_length=50):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = [src_vocab[token] for token in tokenize(sentence)]\n",
    "        input_tensor = torch.tensor(input_tensor, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[tgt_vocab['<sos>']]])\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "\n",
    "            if topi.item() == tgt_vocab['<eos>']:\n",
    "                break  # Only break if <EOS> is genuinely predicted\n",
    "            else:\n",
    "                decoded_words.append(rev_tgt_vocab[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return ' '.join(decoded_words)\n",
    "\n",
    "# Example translation\n",
    "example_sentence = \"The baby cries\"\n",
    "translated_sentence = translate(example_sentence, enc, dec, en_vocab, fr_vocab, rev_fr_vocab)\n",
    "print(f'Translated: {translated_sentence}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T03:44:18.274766300Z",
     "start_time": "2024-04-09T03:42:36.499503100Z"
    }
   },
   "id": "a29a1724f78df830",
   "execution_count": 160
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input index: 196, Embedding size: 186\n",
      "Max target index: 185, Embedding size: 202\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[162], line 232\u001B[0m\n\u001B[0;32m    227\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Train Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mavg_train_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Train Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mavg_train_accuracy\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Val Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mavg_val_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Val Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mavg_val_accuracy\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    231\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m--> 232\u001B[0m \u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdec\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menc_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdec_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    234\u001B[0m \u001B[38;5;66;03m# Translation function\u001B[39;00m\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtranslate\u001B[39m(sentence, encoder, decoder, src_vocab, tgt_vocab, rev_tgt_vocab, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m):\n",
      "Cell \u001B[1;32mIn[162], line 218\u001B[0m, in \u001B[0;36mtrain_loop\u001B[1;34m(num_epochs, train_dataloader, val_dataloader, encoder, decoder, enc_optimizer, dec_optimizer, criterion)\u001B[0m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m src, tgt \u001B[38;5;129;01min\u001B[39;00m train_dataloader:\n\u001B[0;32m    217\u001B[0m     src, tgt \u001B[38;5;241m=\u001B[39m src\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m), tgt\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m--> 218\u001B[0m     loss, accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtgt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menc_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdec_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    219\u001B[0m     total_train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n\u001B[0;32m    220\u001B[0m     total_train_accuracy \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m accuracy\n",
      "Cell \u001B[1;32mIn[162], line 133\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001B[0m\n\u001B[0;32m    130\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(max_length, encoder\u001B[38;5;241m.\u001B[39mhidden_size)\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ei \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(input_length):\n\u001B[1;32m--> 133\u001B[0m     encoder_output, encoder_hidden \u001B[38;5;241m=\u001B[39m \u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m[\u001B[49m\u001B[43mei\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder_hidden\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    134\u001B[0m     encoder_outputs[ei] \u001B[38;5;241m=\u001B[39m encoder_output[\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    136\u001B[0m decoder_input \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([[fr_vocab[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m<sos>\u001B[39m\u001B[38;5;124m'\u001B[39m]]])\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[162], line 56\u001B[0m, in \u001B[0;36mEncoderGRU.forward\u001B[1;34m(self, input, hidden)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m, hidden):\n\u001B[1;32m---> 56\u001B[0m     embedded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     57\u001B[0m     output, hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgru(embedded, hidden)\n\u001B[0;32m     58\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output, hidden\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    163\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2233\u001B[0m, in \u001B[0;36membedding\u001B[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[0;32m   2227\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[0;32m   2228\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[0;32m   2229\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[0;32m   2230\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[0;32m   2231\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[0;32m   2232\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[1;32m-> 2233\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mIndexError\u001B[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "def build_vocab(sentences):\n",
    "    tokens = [token for sentence in sentences for token in sentence]\n",
    "    vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
    "    vocab.update({token: i+3 for i, token in enumerate(set(tokens))})\n",
    "    return vocab\n",
    "\n",
    "# Custom dataset class\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_sentences, tgt_sentences, src_vocab, tgt_vocab):\n",
    "        self.src_sentences = [[src_vocab[token] for token in ['<sos>'] + sentence + ['<eos>']] for sentence in src_sentences]\n",
    "        self.tgt_sentences = [[tgt_vocab[token] for token in ['<sos>'] + sentence + ['<eos>']] for sentence in tgt_sentences]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_sentence = self.src_sentences[idx]\n",
    "        tgt_sentence = self.tgt_sentences[idx]\n",
    "        return torch.tensor(src_sentence, dtype=torch.long), torch.tensor(tgt_sentence, dtype=torch.long)\n",
    "\n",
    "french_to_english = [(fr, en) for en, fr in english_to_french]\n",
    "\n",
    "# Tokenize and prepare the dataset\n",
    "tokenized_fr = [tokenize(fr) for fr, _ in french_to_english]\n",
    "tokenized_en = [tokenize(en) for _, en in french_to_english]\n",
    "\n",
    "fr_vocab = build_vocab(tokenized_fr)\n",
    "en_vocab = build_vocab(tokenized_en)\n",
    "rev_en_vocab = {v: k for k, v in en_vocab.items()}\n",
    "\n",
    "train_dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_vocab, en_vocab)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Encoder definition\n",
    "class EncoderGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout=0):\n",
    "        super(EncoderGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.n_layers, 1, self.hidden_size)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden: [1, batch size, hid dim], encoder_outputs: [src len, batch size, hid dim]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        hidden = hidden.repeat(src_len, 1, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        return F.softmax(attention, dim=0)\n",
    "\n",
    "class AttnDecoderGRU(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size, n_layers=1, dropout_p=0.1):\n",
    "        super(AttnDecoderGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attention = Attention(hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size + hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        attn_weights = self.attention(hidden, encoder_outputs)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs.permute(1, 0, 2))\n",
    "        gru_input = torch.cat((embedded, attn_applied.permute(1, 0, 2)), dim=2)\n",
    "        output, hidden = self.gru(gru_input, hidden)\n",
    "        output = self.out(torch.cat((output.squeeze(0), attn_applied.squeeze(1)), dim=1))\n",
    "        return F.log_softmax(output, dim=1), hidden\n",
    "\n",
    "\n",
    "# Initialize models, optimizers, and loss function\n",
    "enc = EncoderGRU(len(en_vocab), 256, 2, 0.5)\n",
    "dec = DecoderGRU(len(fr_vocab), 256, 2, 0.5)\n",
    "enc_optimizer = optim.SGD(enc.parameters(), lr=0.01)\n",
    "dec_optimizer = optim.SGD(dec.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=50):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "    correct = 0  # To calculate accuracy\n",
    "    \n",
    "    # Add this inside your train function, right before the loop over input_length starts\n",
    "    max_input_index = torch.max(input_tensor).item()\n",
    "    print(f\"Max input index: {max_input_index}, Embedding size: {enc.embedding.num_embeddings}\")\n",
    "\n",
    "# Do the same for the target tensor if necessary\n",
    "    max_target_index = torch.max(target_tensor).item()\n",
    "    print(f\"Max target index: {max_target_index}, Embedding size: {dec.embedding.num_embeddings}\")\n",
    "\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[fr_vocab['<sos>']]])\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "        if decoder_input.item() == target_tensor[di].item():\n",
    "            correct += 1\n",
    "\n",
    "        if decoder_input.item() == fr_vocab['<eos>']:\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    accuracy = correct / target_length  # Calculate accuracy\n",
    "\n",
    "    return loss.item() / target_length, accuracy\n",
    "\n",
    "# Validation function\n",
    "def validate(encoder, decoder, dataloader, criterion, max_length=50):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src, tgt = src.squeeze(0), tgt.squeeze(0)\n",
    "            loss, accuracy = evaluate(src, tgt, encoder, decoder, criterion, max_length)\n",
    "            total_loss += loss\n",
    "            total_accuracy += accuracy\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_accuracy = total_accuracy / len(dataloader)\n",
    "    return avg_loss, avg_accuracy\n",
    "\n",
    "# Evaluate function\n",
    "def evaluate(src_tensor, tgt_tensor, encoder, decoder, criterion, max_length=50):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    input_length = src_tensor.size(0)\n",
    "    target_length = tgt_tensor.size(0)\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(src_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[fr_vocab['<sos>']]])\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        if topi.item() == tgt_tensor[di].item():\n",
    "            correct += 1\n",
    "        decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        loss += criterion(decoder_output, tgt_tensor[di].unsqueeze(0))\n",
    "        if decoder_input.item() == fr_vocab['<eos>']:\n",
    "            break\n",
    "\n",
    "    accuracy = correct / target_length\n",
    "    return loss.item(), accuracy\n",
    "\n",
    "def train_loop(num_epochs, train_dataloader, val_dataloader, encoder, decoder, enc_optimizer, dec_optimizer, criterion):\n",
    "    for epoch in range(num_epochs):\n",
    "        total_train_loss = 0\n",
    "        total_train_accuracy = 0\n",
    "\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        for src, tgt in train_dataloader:\n",
    "            src, tgt = src.squeeze(0), tgt.squeeze(0)\n",
    "            loss, accuracy = train(src, tgt, encoder, decoder, enc_optimizer, dec_optimizer, criterion)\n",
    "            total_train_loss += loss\n",
    "            total_train_accuracy += accuracy\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "        avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n",
    "\n",
    "        avg_val_loss, avg_val_accuracy = validate(encoder, decoder, val_dataloader, criterion)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_accuracy:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {avg_val_accuracy:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "train_loop(50, train_dataloader, val_dataloader, enc, dec, enc_optimizer, dec_optimizer, criterion)\n",
    "\n",
    "# Translation function\n",
    "def translate(sentence, encoder, decoder, src_vocab, tgt_vocab, rev_tgt_vocab, max_length=50):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = [src_vocab[token] for token in tokenize(sentence)]\n",
    "        input_tensor = torch.tensor(input_tensor, dtype=torch.long).view(-1, 1)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "        for ei in range(input_tensor.size(0)):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[tgt_vocab['<sos>']]])\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "\n",
    "            if topi.item() == tgt_vocab['<eos>']:\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(rev_tgt_vocab[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return ' '.join(decoded_words)\n",
    "    \n",
    "french_sentences = [ \"Je suis fatigué.\",]\n",
    "for sentence in french_sentences:\n",
    "    translated_sentence = translate(sentence, enc, dec, fr_vocab, en_vocab, rev_en_vocab)\n",
    "    print(f'French: {sentence}\\nTranslated: {translated_sentence}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T03:46:26.222615200Z",
     "start_time": "2024-04-09T03:46:26.024553400Z"
    }
   },
   "id": "3c5fd84d87d860cb",
   "execution_count": 162
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-09T03:44:18.497343500Z"
    }
   },
   "id": "9fbb5a10b6628035"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
