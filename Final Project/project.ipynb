{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-12T20:58:39.180269800Z",
     "start_time": "2024-04-12T20:56:55.999973900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1: 1 0.2171875 0.2569444444444444 0.253125 0.2569444444444444 0.253125 0.3194444444444444 0.2171875 0.3194444444444444\n",
      "Line 2: 0 0.2421875 0.2569444444444444 0.27734375 0.2569444444444444 0.27734375 0.3236111111111111 0.2421875 0.3236111111111111\n",
      "Line 3: 1 0.26953125 0.2569444444444444 0.303125 0.2569444444444444 0.303125 0.3236111111111111 0.26953125 0.3236111111111111\n",
      "Line 4: 0 0.29296875 0.25555555555555554 0.32890625 0.25555555555555554 0.32890625 0.32222222222222224 0.29296875 0.32222222222222224\n",
      "Line 5: 1 0.31953125 0.25972222222222224 0.353125 0.25972222222222224 0.353125 0.32222222222222224 0.31953125 0.32222222222222224\n",
      "Line 6: 1 0.36015625 0.25555555555555554 0.39296875 0.25555555555555554 0.39296875 0.3194444444444444 0.36015625 0.3194444444444444\n",
      "Processing train data...\n",
      "Finished processing 8691 images from train set.\n",
      "Processing valid data...\n",
      "Finished processing 2483 images from valid set.\n",
      "Processing test data...\n",
      "Finished processing 1242 images from test set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def parse_annotation(labels_path):\n",
    "    objects = []\n",
    "    with open(labels_path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            coordinates = list(map(float, parts[1:]))  # Convert all to float\n",
    "            xs = coordinates[0::2]  # Extract all x coordinates\n",
    "            ys = coordinates[1::2]  # Extract all y coordinates\n",
    "            xmin, xmax = min(xs), max(xs)\n",
    "            ymin, ymax = min(ys), max(ys)\n",
    "            objects.append((class_id, xmin, ymin, xmax, ymax))\n",
    "    return objects\n",
    "\n",
    "# def check_annotation_example(annotation_dir):\n",
    "#     example_annotation_file = next(os.path.join(annotation_dir, f) for f in os.listdir(annotation_dir) if f.endswith('.txt'))\n",
    "#     with open(example_annotation_file, 'r') as file:\n",
    "#         for i, line in enumerate(file):\n",
    "#             print(f\"Line {i + 1}: {line.strip()}\")\n",
    "#             if i >= 5:  # Print only the first 5 lines\n",
    "#                 break\n",
    "# \n",
    "# # Call this function to check the format\n",
    "# annotation_dir = os.path.join(r'C:/Users/SirM/Desktop/Swayam/Intro to Deep Learning/Intro-to-Deep-Learning/Final Project/PKLot.v1-raw.yolov8-obb', 'train', 'labels')  # Adjust as necessary\n",
    "# check_annotation_example(annotation_dir)\n",
    "\n",
    "def resize_image(image, new_width, new_height, boxes):\n",
    "    width, height = image.size\n",
    "    resize_ratio_w = new_width / width\n",
    "    resize_ratio_h = new_height / height\n",
    "    image = image.resize((new_width, new_height))\n",
    "    \n",
    "    resized_boxes = []\n",
    "    for box in boxes:\n",
    "        class_id, x1, y1, x2, y2 = box\n",
    "        resized_boxes.append((\n",
    "            class_id,\n",
    "            x1 * resize_ratio_w,\n",
    "            y1 * resize_ratio_h,\n",
    "            x2 * resize_ratio_w,\n",
    "            y2 * resize_ratio_h\n",
    "        ))\n",
    "    return image, resized_boxes\n",
    "\n",
    "def preprocess_image(image_path, annotation_path, target_size=(128, 128)):\n",
    "    image = Image.open(image_path)\n",
    "    boxes = parse_annotation(annotation_path)\n",
    "    \n",
    "    image, boxes = resize_image(image, target_size[0], target_size[1], boxes)\n",
    "    image_np = np.array(image) / 255.0  # Normalize pixel values\n",
    "    \n",
    "    return image_np, boxes\n",
    "\n",
    "def process_directory(data_dir, annotation_dir, target_size=(128, 128)):\n",
    "    processed_data = []\n",
    "    for img_filename in os.listdir(data_dir):\n",
    "        if img_filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(data_dir, img_filename)\n",
    "            annotation_path = os.path.join(annotation_dir, img_filename.replace('.jpg', '.txt'))\n",
    "            processed_image, processed_boxes = preprocess_image(image_path, annotation_path, target_size)\n",
    "            processed_data.append((processed_image, processed_boxes))\n",
    "    return processed_data\n",
    "\n",
    "# Example usage\n",
    "dataset_base = r'C:/Users/SirM/Desktop/Swayam/Intro to Deep Learning/Intro-to-Deep-Learning/Final Project/PKLot.v1-raw.yolov8-obb'\n",
    "partitions = ['train', 'valid', 'test']\n",
    "target_size = (128, 128)  # Change as required by your model\n",
    "\n",
    "all_data = {}\n",
    "for part in partitions:\n",
    "    print(f\"Processing {part} data...\")\n",
    "    images_dir = os.path.join(dataset_base, part, 'images')\n",
    "    annotations_dir = os.path.join(dataset_base, part, 'labels')  # Adjust if different\n",
    "    all_data[part] = process_directory(images_dir, annotations_dir, target_size)\n",
    "    print(f\"Finished processing {len(all_data[part])} images from {part} set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b64968c2e3e4e559"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
